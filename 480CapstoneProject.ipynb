{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd435b7b-dc4c-432d-ad6f-f8911845290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "\n",
    "#data = np.load(\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/results_dataset/2019-11-27--10_24_59/000200/behaviour_25.npy\", allow_pickle=True)\n",
    "data_november_29 = []\n",
    "for i in range(200, 315):\n",
    "    data = np.load(\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/results_dataset/2019-11-27--10_24_59/000\" + str(i) + \"/behaviour_15.npy\", allow_pickle=True)\n",
    "    data_november_29.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243e4f3f-1e7b-4c9a-8b77-a91d46efe9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "def load_frames(video_index):\n",
    "    video = cv2.VideoCapture(\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/PIGS291119/000\" + str(video_index) + \"/color.mp4\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "\n",
    "    while video.isOpened():\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    video.release()\n",
    "    return frames\n",
    "\n",
    "def load_times(video_index):\n",
    "    times = []\n",
    "    with open(\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/PIGS291119/000\" + str(video_index) + \"/times.txt\", \"r\") as file:\n",
    "        for line in file:\n",
    "            times.append(get_time(line.strip()))\n",
    "    return times\n",
    "\n",
    "def is_eating(i):\n",
    "    if i == 4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def at_feeder(i):\n",
    "    return i == 1\n",
    "\n",
    "def display_frame(frame_data, frame):\n",
    "    frame_copy = frame.copy()\n",
    "    i = 9\n",
    "    x1 = int(frame_data[1])\n",
    "    y1 = int(frame_data[2])\n",
    "    x2 = int(frame_data[3])\n",
    "    y2 = int(frame_data[4])\n",
    "    #print(data[i][1][0])\n",
    "    cv2.rectangle(frame_copy, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=2)\n",
    "    frame_copy_rgb = cv2.cvtColor(frame_copy, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('Frame', frame_copy)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def get_time(timestamp):\n",
    "    return datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%S.%f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ed3f6c9-dc97-4989-8805-52710ef39eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Views a single image\n",
    "import cv2\n",
    "\n",
    "# Define the paths to the annotation and image files\n",
    "annotation_file = 'C:/Users/calvi/Desktop/School/ANSC480/DataCode/dataset/labels/train/000451.txt'  # YOLO annotation file\n",
    "image_file = 'C:/Users/calvi/Desktop/School/ANSC480/DataCode/dataset/images/train/000451.jpg'  # Corresponding image file\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(image_file)\n",
    "\n",
    "# Get the image dimensions\n",
    "img_height, img_width, _ = image.shape\n",
    "\n",
    "# Read the annotation file\n",
    "with open(annotation_file, 'r') as f:\n",
    "    annotations = f.readlines()\n",
    "\n",
    "# Loop through each annotation and draw the corresponding bounding box\n",
    "for annotation in annotations:\n",
    "    # Split the annotation into components\n",
    "    parts = annotation.strip().split()\n",
    "    class_id = int(parts[0])  # Class ID\n",
    "    x_center = float(parts[1])  # Normalized x-center\n",
    "    y_center = float(parts[2])  # Normalized y-center\n",
    "    width = float(parts[3])  # Normalized width\n",
    "    height = float(parts[4])  # Normalized height\n",
    "    \n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    x_center = int(x_center * img_width)\n",
    "    y_center = int(y_center * img_height)\n",
    "    width = int(width * img_width)\n",
    "    height = int(height * img_height)\n",
    "\n",
    "    # Calculate the top-left and bottom-right corners of the bounding box\n",
    "    x1 = x_center - width // 2\n",
    "    y1 = y_center - height // 2\n",
    "    x2 = x_center + width // 2\n",
    "    y2 = y_center + height // 2\n",
    "\n",
    "    # Draw the bounding box on the image\n",
    "    color = (0, 255, 0)  # Green color for the bounding box\n",
    "    thickness = 2  # Line thickness\n",
    "    image = cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    # Optionally, put the class ID text near the bounding box\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    image = cv2.putText(image, str(class_id), (x1, y1 - 10), font, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow('Image with Bounding Boxes', image)\n",
    "\n",
    "# Wait for a key press and close the image window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ae450f1-cc74-4ed5-8293-a6c933e59382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Views a single image, annotation from the annotated dataset\n",
    "from PIL import Image, ImageDraw\n",
    "image_file = 'C:/Users/calvi/Desktop/School/ANSC480/DataCode/dataset/images/train/000025.jpg'\n",
    "# Load the annotations\n",
    "with open(\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_11_28/000113/output.json\", \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Select the frame numbers you want to inspect manually\n",
    "frames_to_check = [5, 10, 15]  # Example frame numbers\n",
    "\n",
    "# Define the image extension (e.g., .jpg)\n",
    "image_extension = \".jpg\"\n",
    "image = Image.open(image_file)\n",
    "# Function to display image with bounding boxes\n",
    "def display_image_with_bbox(image_path, bbox):\n",
    "    \n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    x, y, w, h = bbox[\"x\"], bbox[\"y\"], bbox[\"width\"], bbox[\"height\"]\n",
    "    draw.rectangle([x, y, x + w, y + h], outline=\"red\", width=2)\n",
    "\n",
    "      # This will open the image in the default viewer\n",
    "\n",
    "# Loop through the selected frames\n",
    "  \n",
    "for pig in annotations[\"objects\"]:\n",
    "    last_fnum_bbox = 0\n",
    "    for frame in pig[\"frames\"]:\n",
    "        fnum = frame[\"frameNumber\"]\n",
    "        if fnum > 25:\n",
    "            break\n",
    "        else:\n",
    "            last_fnum_bbox = frame[\"bbox\"]        \n",
    "    display_image_with_bbox(image_path, last_fnum_bbox)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "355439aa-85fc-4b0c-9bd4-3f1b6d3319c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4 0.426172 0.425694 0.210156 0.215278', '5 0.635938 0.718056 0.140625 0.255556', '0 0.865234 0.499306 0.111719 0.234722', '1 0.640625 0.332639 0.150000 0.154167', '2 0.497656 0.258333 0.193750 0.188889', '3 0.261328 0.792361 0.252344 0.404167', '6 0.229687 0.588889 0.182812 0.294444', '7 0.648828 0.684722 0.167969 0.291667']\n"
     ]
    }
   ],
   "source": [
    "print(frame_annotations[25])\n",
    "framelists[\"objects\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269825b9-5d3a-4492-9788-168fd3c1b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates folder with bounding boxes on the images, currently set to just pigs eating at feeder, each new instance gets its own frame\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Directory to save images with bounding boxes\n",
    "output_dir = \"bounded_pigs_np\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through videos and npy files\n",
    "for i in range(0, len(data_november_29)): #len(data_november_29) or 50\n",
    "    frames = load_frames(200 + i)\n",
    "    for tracklet in range(0, data_november_29[i].shape[0]):\n",
    "        if data_november_29[i].size == 0:\n",
    "            continue\n",
    "        pig_data = data_november_29[i][tracklet]\n",
    "        pig_times = load_times(200 + i) #Clips start at 200 for November 29th\n",
    "        \n",
    "        for frame_data in pig_data:\n",
    "            if is_eating(frame_data[13]) and at_feeder(frame_data[12]):\n",
    "                frame = frames[int(frame_data[0])]\n",
    "                x1 = int(frame_data[1])\n",
    "                y1 = int(frame_data[2])\n",
    "                x2 = int(frame_data[3])\n",
    "                y2 = int(frame_data[4])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                save_path = os.path.join(output_dir, f\"{video_index}_{frame_count:05}.jpg\")\n",
    "                cv2.imwrite(save_path, frame)\n",
    "                saved_frames += 1\n",
    "                frame_count += 1\n",
    "#            cv2.putText(frame, f\"Pig {pig_id}\", (x1, y1 - 10),\n",
    " #                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "    \n",
    "\n",
    "    print(f\"✅ Video {video_index}: Saved {saved_frames} annotated frames\")\n",
    "\n",
    "print(\"🎉 All videos processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd1bc948-5470-48c1-83f2-abbde9f0a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 1988 cropped pig images by tracklet.\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "#Crop november 29th pigs based on video and tracklet\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Assumes these functions/variables are defined elsewhere:\n",
    "# - data_november_29: list of np.arrays for each video\n",
    "# - load_frames(video_index): loads list of frames for the given video index\n",
    "\n",
    "output_base = \"cropped_pigs_by_tracklet\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "total_crops = 0\n",
    "\n",
    "for video_index in range(len(data_november_29)):\n",
    "    frames = load_frames(200 + video_index)  # Clip numbers start at 200\n",
    "\n",
    "    video_data = data_november_29[video_index]\n",
    "    if video_data.size == 0:\n",
    "        continue\n",
    "\n",
    "    for tracklet_index in range(video_data.shape[0]):\n",
    "        tracklet = video_data[tracklet_index]\n",
    "\n",
    "        # Create output directory: cropped_pigs_by_tracklet/{video_index}/{tracklet_index}/\n",
    "        out_dir = os.path.join(output_base, f\"{video_index}\", f\"{tracklet_index}\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        frame_data = tracklet[0]\n",
    "        frame_num = int(frame_data[0])\n",
    "        x1, y1 = int(frame_data[1]), int(frame_data[2])\n",
    "        x2, y2 = int(frame_data[3]), int(frame_data[4])\n",
    "\n",
    "        if frame_num >= len(frames):\n",
    "            continue\n",
    "\n",
    "        frame = frames[frame_num]\n",
    "        crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "        out_path = os.path.join(out_dir, f\"{frame_num:04}.jpg\")\n",
    "        cv2.imwrite(out_path, crop)\n",
    "        total_crops += 1\n",
    "\n",
    "    del frames  # Save memory\n",
    "\n",
    "print(f\"✅ Saved {total_crops} cropped pig images by tracklet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173355c4-a54f-49ab-8c6c-67c8cae281c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames: 1800\n",
      "✅ Processed and saved 1800 frames with bounding boxes.\n"
     ]
    }
   ],
   "source": [
    "#creates a folder of bounding boxes for \"annotated ground truth\" data\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Replace with your actual JSON file path\n",
    "json_file = \"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_11_05/000009/output.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    framelists = json.load(f)\n",
    "\n",
    "# Video path (for extracting frames)\n",
    "video_path = \"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_11_05/000009/color.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "max_frame_count = 0  # For loading in different days, you'll need to adjust the names of the files to avoid overlap\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    max_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total number of frames:\", max_frame_count)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Image dimensions (required for normalization)\n",
    "IMG_WIDTH = 1280  # adjust to match your dataset\n",
    "IMG_HEIGHT = 720\n",
    "\n",
    "# Output directory for images with bounding boxes\n",
    "output_dir_bounded = \"dataset/bounded_pigs\"\n",
    "os.makedirs(output_dir_bounded, exist_ok=True)\n",
    "\n",
    "def convert_to_yolo_bbox(x, y, w, h):\n",
    "    x_center = (x + w / 2) / IMG_WIDTH\n",
    "    y_center = (y + h / 2) / IMG_HEIGHT\n",
    "    width = w / IMG_WIDTH\n",
    "    height = h / IMG_HEIGHT\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "# Group annotations by frameNumber\n",
    "frame_annotations = {}\n",
    "last_seen = {}\n",
    "\n",
    "for pig in framelists[\"objects\"]:\n",
    "    pig_id = int(pig[\"id\"])  # class label\n",
    "    dict_by_frame = {\n",
    "        item[\"frameNumber\"]: {k: v for k, v in item.items() if k != \"frame_number\"}\n",
    "        for item in pig[\"frames\"]\n",
    "        }\n",
    "    for fnum in range(0, max_frame_count):\n",
    "        frame_id = fnum // 3\n",
    "        if frame_id in dict_by_frame.keys():\n",
    "            bbox = dict_by_frame[frame_id][\"bbox\"]\n",
    "            x, y, w, h = bbox[\"x\"], bbox[\"y\"], bbox[\"width\"], bbox[\"height\"]\n",
    "            x_c, y_c, bw, bh = convert_to_yolo_bbox(x, y, w, h)\n",
    "            label = f\"{pig_id} {x_c:.6f} {y_c:.6f} {bw:.6f} {bh:.6f}\"\n",
    "            frame_annotations.setdefault(fnum, []).append(label)\n",
    "            last_seen[pig_id] = label\n",
    "        else:\n",
    "            frame_annotations.setdefault(fnum, []).append(last_seen[pig_id])\n",
    "\n",
    "# Iterate through frames and draw bounding boxes on images\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_idx = 0\n",
    "bounded_image_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Check if this frame has annotations\n",
    "    if frame_idx in frame_annotations:\n",
    "        # Get annotations for the current frame\n",
    "        for annotation in frame_annotations[frame_idx]:\n",
    "            parts = annotation.split()\n",
    "            pig_id = int(parts[0])\n",
    "            # Convert YOLO bounding box to pixel coordinates\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            x = int((x_center - width / 2) * IMG_WIDTH)\n",
    "            y = int((y_center - height / 2) * IMG_HEIGHT)\n",
    "            w = int(width * IMG_WIDTH)\n",
    "            h = int(height * IMG_HEIGHT)\n",
    "\n",
    "            # Draw the bounding box and label on the image\n",
    "            color = (0, 255, 0)  # Green color for bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "            # Add the pig ID text\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(frame, f\"Pig {pig_id}\", (x, y - 10), font, 0.9, color, 2)\n",
    "\n",
    "        # Save the modified image\n",
    "        output_image_path = os.path.join(output_dir_bounded, f\"frame_{frame_idx+fnum_offset:06}.jpg\")\n",
    "        cv2.imwrite(output_image_path, frame)\n",
    "        bounded_image_count += 1\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"✅ Processed and saved {bounded_image_count} frames with bounding boxes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa60293-e199-42d6-ad65-f94a75a01e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames: 1800\n",
      "✅ Labels converted and saved.\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "#Extract frame annotation data for YOLO training\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Replace with your actual JSON file path\n",
    "#json_file = \"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_11_28/000113/output.json\"\n",
    "json_file = \"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_12_02/000005/output.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    framelists = json.load(f)\n",
    "\n",
    "#video_path = \"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_11_28/000113/color.mp4\"  # Replace with your actual path\n",
    "video_path = \"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/2019_12_02/000005/color.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "max_frame_count = 0\n",
    "fnum_offset = 0 #For loading in different days, you'll need to adjust the names of the files to avoid overlap\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "else:\n",
    "    max_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"Total number of frames:\", max_frame_count)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Image dimensions (required for normalization)\n",
    "IMG_WIDTH = 1280  # adjust to match your dataset\n",
    "IMG_HEIGHT = 720\n",
    "\n",
    "# Output directory for YOLO label files\n",
    "output_dir_train = \"dataset/labels/train\"\n",
    "output_dir_test = \"dataset/labels/test\"\n",
    "output_dir_val = \"dataset/labels/val\"\n",
    "#os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_dir_train, exist_ok=True)\n",
    "os.makedirs(output_dir_test, exist_ok=True)\n",
    "os.makedirs(output_dir_val, exist_ok=True)\n",
    "\n",
    "def convert_to_yolo_bbox(x, y, w, h):\n",
    "    x_center = (x + w / 2) / IMG_WIDTH\n",
    "    y_center = (y + h / 2) / IMG_HEIGHT\n",
    "    width = w / IMG_WIDTH\n",
    "    height = h / IMG_HEIGHT\n",
    "    return x_center, y_center, width, height\n",
    "\n",
    "# Group annotations by frameNumber\n",
    "frame_annotations = {}\n",
    "last_seen = {}\n",
    "\n",
    "for pig in framelists[\"objects\"]:\n",
    "    pig_id = int(pig[\"id\"])  # class label\n",
    "    dict_by_frame = {\n",
    "        item[\"frameNumber\"]: {k: v for k, v in item.items() if k != \"frame_number\"}\n",
    "        for item in pig[\"frames\"]\n",
    "        }\n",
    "    for fnum in range(0, max_frame_count):\n",
    "        \n",
    "        #if not frame.get(\"visible\", False):\n",
    "        #    continue\n",
    "        #fnum = frame[\"frameNumber\"]\n",
    "        frame_id = fnum // 3 #They measured every third frame\n",
    "        if frame_id in dict_by_frame.keys():\n",
    "            bbox = dict_by_frame[frame_id][\"bbox\"]\n",
    "            x, y, w, h = bbox[\"x\"], bbox[\"y\"], bbox[\"width\"], bbox[\"height\"]\n",
    "            x_c, y_c, bw, bh = convert_to_yolo_bbox(x, y, w, h)\n",
    "            label = f\"{pig_id} {x_c:.6f} {y_c:.6f} {bw:.6f} {bh:.6f}\"\n",
    "            frame_annotations.setdefault(fnum, []).append(label)\n",
    "            \n",
    "            last_seen[pig_id] = label\n",
    "        else:\n",
    "            frame_annotations.setdefault(fnum, []).append(last_seen[pig_id])\n",
    "\n",
    "#all_frame_nums = sorted(frame_annotations.keys())\n",
    "#for fnum in all_frame_nums:\n",
    "#    present_ids = {int(lbl.split()[0]) for lbl in frame_annotations[fnum]}\n",
    "#    for pig_id in range(8):  # Ensure pigs 0–7\n",
    "#        if pig_id not in present_ids and pig_id in last_seen:\n",
    "            # Use the last seen bbox if pig missing\n",
    "#            frame_annotations[fnum].append(last_seen[pig_id])\n",
    "\n",
    "# Save .txt file for each frame\n",
    "for fnum, labels in frame_annotations.items():\n",
    "    label_path = os.path.join(output_dir_train, f\"{fnum+fnum_offset:06}.txt\")\n",
    "    if fnum > len(frame_annotations.items()) * 0.9:\n",
    "        label_path = os.path.join(output_dir_val, f\"{fnum+fnum_offset:06}.txt\")\n",
    "    elif fnum > len(frame_annotations.items()) * 0.7:\n",
    "        label_path = os.path.join(output_dir_test, f\"{fnum+fnum_offset:06}.txt\")\n",
    "    with open(label_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(labels))\n",
    "\n",
    "print(\"✅ Labels converted and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0af226-d3ec-4031-9615-ffd45830b998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b691ce0-f4c4-4da5-8f7e-e79267565504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(framelists[\"objects\"][0][\"frames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e8c1c775-9c8f-4489-8607-0ddd767b2f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n",
      "✅ Saved 480 cropped images.\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "#creates cropped images from annotated data\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "# Input video and annotation\n",
    "paths = [\"2019_11_05/000002\", \"2019_11_05/000009\", \"2019_11_11/000016\",\"2019_11_11/000028\",\"2019_11_11/000036\", \"2019_11_15/000033\",\n",
    "        \"2019_11_22/000010\",\"2019_11_28/000113\",\"2019_12_02/000005\",\"2019_12_02/000208\",]\n",
    "iter_offset = 0\n",
    "for path in paths:\n",
    "    video_path = f\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/{path}/color.mp4\"\n",
    "    json_file = f\"C:/Users/calvi/Desktop/School/ANSC480/DataCode/annotated/{path}/output.json\"\n",
    "    \n",
    "    with open(json_file, \"r\") as f:\n",
    "        framelists = json.load(f)\n",
    "    \n",
    "    # Output directory for cropped images by class\n",
    "    base_output_dir = \"cropped_pigs\"\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    for i in range(8):\n",
    "        os.makedirs(os.path.join(base_output_dir, str(i)), exist_ok=True)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    max_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Parse JSON annotations\n",
    "    frame_data_by_id = {}\n",
    "    last_seen = {}\n",
    "    for pig in framelists[\"objects\"]:\n",
    "        pig_id = int(pig[\"id\"])  # class label\n",
    "        dict_by_frame = {\n",
    "            item[\"frameNumber\"]: {k: v for k, v in item.items() if k != \"frame_number\"}\n",
    "            for item in pig[\"frames\"]\n",
    "            }\n",
    "        for fnum in range(0, max_frame_count, 30):\n",
    "            \n",
    "            #if not frame.get(\"visible\", False):\n",
    "            #    continue\n",
    "            #fnum = frame[\"frameNumber\"]\n",
    "            frame_id = fnum // 3 #They measured every third frame\n",
    "            if frame_id in dict_by_frame.keys():\n",
    "                bbox = dict_by_frame[frame_id][\"bbox\"]\n",
    "                frame_data_by_id.setdefault(fnum, []).append((pig_id, bbox))\n",
    "                \n",
    "                last_seen[pig_id] = bbox\n",
    "            else:\n",
    "                frame_data_by_id.setdefault(fnum, []).append((pig_id, last_seen[pig_id]))\n",
    "    \n",
    "    # Extract bounding boxes as images\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frame_idx = 0\n",
    "    count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_idx >= max_frame_count:\n",
    "            break\n",
    "    \n",
    "        if frame_idx in frame_data_by_id:\n",
    "            for pig_id, bbox in frame_data_by_id[frame_idx]:\n",
    "                x, y, w, h = int(bbox[\"x\"]), int(bbox[\"y\"]), int(bbox[\"width\"]), int(bbox[\"height\"])\n",
    "                crop = frame[y:y+h, x:x+w]\n",
    "                out_path = os.path.join(base_output_dir, str(pig_id), f\"{frame_idx+iter_offset:06}_{pig_id}.jpg\")\n",
    "                cv2.imwrite(out_path, crop)\n",
    "                count += 1\n",
    "    \n",
    "        frame_idx += 1\n",
    "    \n",
    "    cap.release()\n",
    "    iter_offset += 1800\n",
    "    print(f\"✅ Saved {count} cropped images.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c2dc8937-340a-44a9-a625-9a2711c5adcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Video saved as annotated_pigs0_video.mp4\n"
     ]
    }
   ],
   "source": [
    "#Creates a video out of the cropped images\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Directory containing cropped pig images\n",
    "image_folder = 'dataset/cropped_pigs'\n",
    "output_video_path = 'annotated_pigs_video.mp4'\n",
    "\n",
    "# Get all image filenames and sort them\n",
    "images = sorted([img for img in os.listdir(image_folder) if img.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "# Make sure there are images\n",
    "if not images:\n",
    "    raise Exception(\"No images found in the folder.\")\n",
    "\n",
    "# Read the first image to get dimensions\n",
    "first_image = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = first_image.shape\n",
    "\n",
    "# Define video codec and create VideoWriter object\n",
    "fps = 10  # Frames per second\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
    "video = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Write each image to the video\n",
    "for image_name in images:\n",
    "    img_path = os.path.join(image_folder, image_name)\n",
    "    frame = cv2.imread(img_path)\n",
    "    video.write(frame)\n",
    "\n",
    "video.release()\n",
    "print(\"✅ Video saved as\", output_video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c746e3-b2a5-408c-95b8-054eec40bf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 1800 frames\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Transfer Frame data for Yolo training\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to your input video\n",
    "output_image_dir_train = \"dataset/images/train\"\n",
    "output_image_dir_test = \"dataset/images/test\"\n",
    "output_image_dir_val = \"dataset/images/val\"\n",
    "\n",
    "os.makedirs(output_image_dir_train, exist_ok=True)\n",
    "os.makedirs(output_image_dir_test, exist_ok=True)\n",
    "os.makedirs(output_image_dir_val, exist_ok=True)\n",
    "\n",
    "#os.makedirs(output_image_dir, exist_ok=True)\n",
    "\n",
    "# Only extract frames that appear in annotation file\n",
    "target_frames = set(frame_annotations.keys())  # from previous step\n",
    "\n",
    "# Open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_idx = 0\n",
    "saved = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_idx in target_frames:\n",
    "        filename = f\"{frame_idx+fnum_offset:06}.jpg\"\n",
    "        out_path = os.path.join(output_image_dir_train, filename)\n",
    "        if frame_idx > len(target_frames) * 0.9:\n",
    "            out_path = os.path.join(output_image_dir_val, filename)\n",
    "        elif frame_idx > len(target_frames) * 0.7:\n",
    "            out_path = os.path.join(output_image_dir_test, filename)\n",
    "        \n",
    "        cv2.imwrite(out_path, frame)\n",
    "        saved += 1\n",
    "\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "print(f\"✅ Saved {saved} frames\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2dd28b8-b62d-4990-8a17-c606f2b2b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/images/val\\001799.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "62e1d027-c4ad-41c9-813b-d89fd5a2cadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.127 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.123  Python-3.10.11 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users/calvi/Desktop/School/ANSC480/DataCode/dataset/datasets.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train21, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, cutmix=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train21\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    432232  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,591,400 parameters, 2,591,384 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 475.067.5 MB/s, size: 288.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\calvi\\Desktop\\School\\ANSC480\\DataCode\\dataset\\labe\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 297.370.3 MB/s, size: 280.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\calvi\\Desktop\\School\\ANSC480\\DataCode\\dataset\\labels\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train21\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train21\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      2.46G      1.234       2.65      1.308        200        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432       0.75      0.367      0.594      0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      2.46G     0.9317     0.9108      1.159        257        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.514       0.52      0.593      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      2.46G     0.8137      0.686       1.08        206        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.522      0.536      0.581      0.446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      2.46G     0.7434     0.6115      1.038        212        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.499        0.5      0.553      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      2.46G     0.6827     0.5606      1.011        204        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.503      0.574      0.565      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      2.46G     0.6406     0.5291     0.9894        240        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432        0.5      0.503       0.55      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      2.46G      0.606     0.5053      0.977        196        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.537      0.563      0.567      0.441\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      2.46G     0.5886     0.4852     0.9672        206        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.552      0.577      0.575      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      2.46G     0.5545     0.4574     0.9507        184        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.497      0.522      0.555      0.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      2.46G     0.5377     0.4388     0.9419        228        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.542       0.58      0.586      0.459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      2.46G     0.5164     0.4258     0.9308        216        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.517      0.574      0.566      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      2.46G     0.4965      0.411     0.9249        199        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.519      0.543      0.555      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      2.46G     0.4888     0.3979     0.9233        202        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.527      0.559      0.553      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      2.46G     0.4696     0.3825     0.9143        249        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.496        0.5      0.565       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      2.46G     0.4594     0.3739     0.9045        217        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.623        0.5      0.563      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      2.46G     0.4467     0.3628     0.9085        231        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.539      0.581      0.555      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      2.46G     0.4413      0.357     0.9036        215        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.486      0.538      0.541      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      2.46G     0.4267     0.3486     0.8982        187        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.519      0.554      0.559      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      2.46G     0.4204     0.3389      0.896        189        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.529       0.58      0.579      0.452\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      2.46G     0.4059      0.328     0.8872        186        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.496      0.585      0.577      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      2.46G     0.4134     0.3293      0.892        246        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.512      0.545      0.554      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      2.46G     0.4031     0.3221     0.8898        221        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.552      0.578      0.564      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      2.46G     0.3912     0.3128     0.8831        218        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.544      0.553      0.566      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      2.46G      0.383      0.306     0.8793        209        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.539      0.616       0.59      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      2.46G     0.3731     0.3002     0.8776        230        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.523      0.549      0.564      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      2.46G     0.3751     0.2987     0.8778        234        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.519      0.547      0.545      0.476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      2.46G     0.3549     0.2866     0.8709        186        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.516      0.583      0.564      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      2.46G     0.3589      0.287     0.8719        222        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.523      0.583      0.561      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      2.46G     0.3498      0.281     0.8691        234        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.509      0.562      0.565      0.469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      2.46G     0.3496     0.2793     0.8679        218        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.528      0.557      0.555      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      2.46G     0.3453     0.2758     0.8662        201        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.499        0.5       0.55      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      2.46G     0.3339     0.2699      0.862        188        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.534      0.554      0.561      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      2.46G      0.329     0.2662     0.8598        292        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432       0.49      0.517      0.549      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      2.46G     0.3247     0.2625     0.8585        248        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.517      0.563      0.554      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      2.46G     0.3184     0.2592      0.858        198        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.522      0.588      0.564      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      2.46G     0.3136     0.2551     0.8574        209        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.528      0.565      0.565      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      2.46G     0.3104     0.2536     0.8538        217        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.511      0.554      0.559      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      2.46G     0.3022     0.2489     0.8516        199        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.515      0.563      0.555      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      2.46G     0.3015     0.2463     0.8524        203        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.521      0.566      0.551       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      2.46G     0.2968     0.2436     0.8525        223        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.522      0.556      0.548      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      2.46G     0.2464     0.2121     0.8068        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.517      0.553      0.539       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      2.46G     0.2272     0.1965     0.8061        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.501      0.545      0.543      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      2.46G     0.2181     0.1908     0.8011        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.529      0.559      0.548      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      2.46G     0.2077     0.1834     0.7946        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.523       0.56      0.551      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      2.46G     0.2047     0.1821     0.7973        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.518      0.556      0.551      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      2.46G     0.1997     0.1773       0.79        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.508      0.548      0.539      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      2.46G     0.1954     0.1751      0.794        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.522      0.547      0.543      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      2.46G     0.1899     0.1706     0.7886        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.509      0.553      0.547      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      2.46G     0.1825     0.1659     0.7901        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.511      0.547      0.542      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      2.46G     0.1781     0.1646     0.7879        104        6\n",
      "                 Class     Images  Instances      Box(P          R      mAP"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.512      0.551      0.542      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.217 hours.\n",
      "Optimizer stripped from runs\\detect\\train21\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from runs\\detect\\train21\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating runs\\detect\\train21\\weights\\best.pt...\n",
      "Ultralytics 8.3.123  Python-3.10.11 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,712 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.497      0.585      0.576      0.492\n",
      "                 pig_1        179        179      0.995          1      0.995      0.977\n",
      "                 pig_2        179        179      0.995          1      0.995      0.987\n",
      "                 pig_3        179        179      0.639          1      0.995      0.953\n",
      "                 pig_4        179        179          0          0       0.17     0.0798\n",
      "                 pig_5        179        179     0.0273     0.0447     0.0463     0.0205\n",
      "                 pig_6        179        179      0.931          1      0.995      0.782\n",
      "                 pig_7        179        179          0          0    0.00364    0.00262\n",
      "                 pig_8        179        179      0.384      0.637      0.412      0.134\n",
      "Speed: 0.5ms preprocess, 1.4ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train21\u001b[0m\n",
      "Ultralytics 8.3.123  Python-3.10.11 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,712 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1598.2251.4 MB/s, size: 281.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\calvi\\Desktop\\School\\ANSC480\\DataCode\\dataset\\labels\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        179       1432      0.496      0.585      0.576      0.492\n",
      "                 pig_1        179        179      0.995          1      0.995       0.98\n",
      "                 pig_2        179        179      0.995          1      0.995      0.986\n",
      "                 pig_3        179        179       0.64          1      0.995      0.953\n",
      "                 pig_4        179        179          0          0       0.17     0.0797\n",
      "                 pig_5        179        179     0.0273     0.0447     0.0465     0.0206\n",
      "                 pig_6        179        179       0.93          1      0.995      0.782\n",
      "                 pig_7        179        179          0          0     0.0036     0.0026\n",
      "                 pig_8        179        179      0.384      0.638      0.412      0.134\n",
      "Speed: 0.4ms preprocess, 4.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train212\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Need to train model to identify each of the 8 pigs at each frame\n",
    "from ultralytics import YOLO\n",
    "# Clear CUDA memory\n",
    "#del model\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "# Load the YOLO model (choose a pre-trained version, e.g., YOLOv5s)\n",
    "yolo_model = YOLO(\"yolo11n.pt\")  # you can choose other pre-trained weights like yolov5m.pt, yolov5l.pt, etc.\n",
    "\n",
    "# Train the model using the data\n",
    "yolo_model.train(data='C:/Users/calvi/Desktop/School/ANSC480/DataCode/dataset/datasets.yaml', epochs=50, imgsz=640, batch=16)\n",
    "val_results = yolo_model.val()\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87db465-0b9a-4de0-a91e-ef9088c0993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract key metrics\n",
    "val_results = results\n",
    "metrics = val_results.results_dict  # This gives a dictionary of metrics\n",
    "# Print to see what's inside\n",
    "print(metrics)\n",
    "# Separate metrics into keys and values\n",
    "keys = list(metrics.keys())\n",
    "values = list(metrics.values())\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(keys, values, color='skyblue')\n",
    "plt.xlabel(\"Value\")\n",
    "plt.title(\"YOLO Validation Metrics\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "dcae4acd-4d98-434a-ad12-82349fea1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 pig_6s, 39.0ms\n",
      "Speed: 4.3ms preprocess, 39.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "frames = load_frames(200+5)\n",
    "frame = frames[1].copy()\n",
    "results = yolo_model(frame)\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "09015cb9-1bd3-4ed8-8790-a7280307d0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 1: Train Loss = 1.1093 | Val Loss = 3.3422 | Val Acc = 0.2271\n",
      "📘 Epoch 2: Train Loss = 0.5585 | Val Loss = 2.8761 | Val Acc = 0.2250\n",
      "📘 Epoch 3: Train Loss = 0.3906 | Val Loss = 3.8595 | Val Acc = 0.2396\n",
      "📘 Epoch 4: Train Loss = 0.2999 | Val Loss = 3.7979 | Val Acc = 0.2146\n",
      "📘 Epoch 5: Train Loss = 0.2416 | Val Loss = 3.9367 | Val Acc = 0.1771\n",
      "📘 Epoch 6: Train Loss = 0.1775 | Val Loss = 4.2340 | Val Acc = 0.2271\n",
      "📘 Epoch 7: Train Loss = 0.1717 | Val Loss = 4.6859 | Val Acc = 0.2458\n",
      "📘 Epoch 8: Train Loss = 0.1707 | Val Loss = 4.4801 | Val Acc = 0.1792\n",
      "📘 Epoch 9: Train Loss = 0.1187 | Val Loss = 4.5436 | Val Acc = 0.1750\n",
      "📘 Epoch 10: Train Loss = 0.0954 | Val Loss = 5.2423 | Val Acc = 0.2542\n",
      "📘 Epoch 11: Train Loss = 0.0917 | Val Loss = 4.2470 | Val Acc = 0.1854\n",
      "📘 Epoch 12: Train Loss = 0.0839 | Val Loss = 4.9440 | Val Acc = 0.2188\n",
      "📘 Epoch 13: Train Loss = 0.0832 | Val Loss = 5.4216 | Val Acc = 0.2687\n",
      "📘 Epoch 14: Train Loss = 0.0769 | Val Loss = 6.0388 | Val Acc = 0.2458\n",
      "📘 Epoch 15: Train Loss = 0.0821 | Val Loss = 5.3810 | Val Acc = 0.2250\n",
      "📘 Epoch 16: Train Loss = 0.0738 | Val Loss = 5.1015 | Val Acc = 0.2583\n",
      "📘 Epoch 17: Train Loss = 0.1055 | Val Loss = 4.7427 | Val Acc = 0.2437\n",
      "📘 Epoch 18: Train Loss = 0.0863 | Val Loss = 4.9307 | Val Acc = 0.2354\n",
      "📘 Epoch 19: Train Loss = 0.0659 | Val Loss = 5.5285 | Val Acc = 0.2042\n",
      "📘 Epoch 20: Train Loss = 0.0387 | Val Loss = 7.0076 | Val Acc = 0.1917\n",
      "📘 Epoch 21: Train Loss = 0.0608 | Val Loss = 5.7262 | Val Acc = 0.1938\n",
      "📘 Epoch 22: Train Loss = 0.0635 | Val Loss = 5.6489 | Val Acc = 0.2625\n",
      "📘 Epoch 23: Train Loss = 0.0589 | Val Loss = 6.2762 | Val Acc = 0.2042\n",
      "📘 Epoch 24: Train Loss = 0.0636 | Val Loss = 5.3915 | Val Acc = 0.2875\n",
      "📘 Epoch 25: Train Loss = 0.0580 | Val Loss = 4.6332 | Val Acc = 0.2479\n",
      "📘 Epoch 26: Train Loss = 0.0508 | Val Loss = 6.4411 | Val Acc = 0.1812\n",
      "📘 Epoch 27: Train Loss = 0.0312 | Val Loss = 6.1290 | Val Acc = 0.1979\n",
      "📘 Epoch 28: Train Loss = 0.0517 | Val Loss = 6.5863 | Val Acc = 0.2167\n",
      "📘 Epoch 29: Train Loss = 0.0406 | Val Loss = 5.4661 | Val Acc = 0.2208\n",
      "📘 Epoch 30: Train Loss = 0.0336 | Val Loss = 5.4298 | Val Acc = 0.2000\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Dataset setup\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder(root='cropped_pigs', transform=transform)\n",
    "val_ds = torchvision.datasets.ImageFolder(root='cropped_pigs_val', transform=transform)\n",
    "#train_size = int(0.8 * len(dataset))\n",
    "#val_size = len(dataset) - train_size\n",
    "#train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model\n",
    "resnet_model = torchvision.models.resnet18(pretrained=True)\n",
    "resnet_model.fc = nn.Linear(resnet_model.fc.in_features, 8)  # 8 pigs\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_model.parameters(), lr=0.0003)\n",
    "\n",
    "for epoch in range(30):\n",
    "    resnet_model.train()\n",
    "    total_train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation phase\n",
    "    resnet_model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "\n",
    "    print(f\"📘 Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f} | Val Acc = {val_accuracy:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(resnet_model.state_dict(), \"pig_classifier.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "21536c2d-ff51-4d9c-b314-b0c1e732060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.3978,  0.8172, -3.7773, -3.1269,  1.7239, -2.3212, -1.9694,  1.1144]], device='cuda:0')\n",
      "✅ True label: 0\n",
      "🔮 Predicted label: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do one sample\n",
    "# Set the model to evaluation mode\n",
    "resnet_model.eval()\n",
    "\n",
    "# Get one sample from the training dataset\n",
    "img, true_label = val_ds[7]  # Change the index if you want a different sample\n",
    "\n",
    "# Add batch dimension and send to device\n",
    "img_tensor = img.unsqueeze(0).to(device)\n",
    "\n",
    "# Run it through the model\n",
    "with torch.no_grad():\n",
    "    output = resnet_model(img_tensor)\n",
    "    predicted_label = output.argmax(dim=1).item()\n",
    "print(output)\n",
    "# Map index to class name\n",
    "class_names = dataset.classes  # From ImageFolder\n",
    "\n",
    "print(f\"✅ True label: {class_names[true_label]}\")\n",
    "print(f\"🔮 Predicted label: {class_names[predicted_label]}\")\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "plt.imshow(F.to_pil_image(img))\n",
    "plt.title(f\"True: {class_names[true_label]}, Predicted: {class_names[predicted_label]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "22d32300-0adf-469c-93c2-e6d04a2dc2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Validation Accuracy: 0.1854\n",
      "🎯 Validation Precision (macro): 0.2017\n",
      "\n",
      "🔍 Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.68      0.46        60\n",
      "           1       0.33      0.03      0.06        60\n",
      "           2       0.00      0.00      0.00        60\n",
      "           3       0.29      0.03      0.06        60\n",
      "           4       0.19      0.43      0.27        60\n",
      "           5       0.00      0.00      0.00        60\n",
      "           6       0.42      0.28      0.34        60\n",
      "           7       0.03      0.02      0.02        60\n",
      "\n",
      "    accuracy                           0.19       480\n",
      "   macro avg       0.20      0.19      0.15       480\n",
      "weighted avg       0.20      0.19      0.15       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Detailed prevision and recall\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "dataset = torchvision.datasets.ImageFolder(root='cropped_pigs_val', transform=transform)\n",
    "resnet_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = resnet_model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Accuracy and Precision (macro = unweighted mean across classes)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')  # or 'weighted'\n",
    "\n",
    "print(f\"\\n📊 Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"🎯 Validation Precision (macro): {precision:.4f}\")\n",
    "\n",
    "# Optional: Show precision/recall/f1 for each pig class\n",
    "print(\"\\n🔍 Detailed classification report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=dataset.classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "842ee299-a924-4dbb-afc6-0e12f6b9b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "import math\n",
    "#imperfect function for estimating what pig is currently the focus of the current frame data\n",
    "def yolo_which_pig(frame, frame_data, prediction):\n",
    "    center_x = (frame_data[3] - frame_data[1]) / 2\n",
    "    center_y = (frame_data[4] - frame_data[2]) / 2\n",
    "    best_center_dist = math.inf\n",
    "    best_center_class = -1\n",
    "    for box in prediction.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        conf = box.conf[0].item()\n",
    "        cls = int(box.cls[0].item())\n",
    "        pred_center_x = (x2-x1)/2\n",
    "        pred_center_y = (y2-y1)/2\n",
    "        if conf > 0.8:\n",
    "            if math.dist((pred_center_x, pred_center_y), (center_x, center_y)) < best_center_dist and math.dist((pred_center_x, pred_center_y), (center_x, center_y)) < 200:\n",
    "                best_center_dist = math.dist((pred_center_x, pred_center_y), (center_x, center_y)) \n",
    "                best_center_class = cls\n",
    "    return best_center_class\n",
    "\n",
    "resnet_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def resnet_which_pig(frame, chosen_model):\n",
    "    device = next(chosen_model.parameters()).device\n",
    "    frame = frame.to(device)\n",
    "    #frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #x1, y1, x2, y2 = int(frame_data[1]), int(frame_data[2]), int(frame_data[3]), int(frame_data[4])\n",
    "    \n",
    "    #crop = frame_rgb[y1:y2, x1:x2]  # Ensure y coordinates come first in slicing\n",
    "\n",
    "    # Transform and add batch dimension\n",
    "    #input_tensor = resnet_transform(crop).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get prediction\n",
    "    predicted_class = 0\n",
    "    with torch.no_grad():\n",
    "        output = chosen_model(frame)\n",
    "        #print(output)\n",
    "        predicted_class = output.argmax(dim=1).item()\n",
    "\n",
    "    #print(f\"Predicted class: {predicted_class}\")\n",
    "    #cv2.imshow('Image with Bounding Box', crop)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "82004221-a05e-408a-add9-d594c2cdf175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#8\n",
    "pigs_feeding_times = [[]] * 8 \n",
    "#pig0_feeding_times = []\n",
    "for i in range(0, len(data_november_29)): #len(data_november_29) or 50\n",
    "    frames = load_frames(200 + i)\n",
    "    if not os.path.exists(f'cropped_pigs_by_tracklet/{i}'): continue\n",
    "    tracklet_dataset = torchvision.datasets.ImageFolder(root=f'cropped_pigs_by_tracklet/{i}', transform=transform)\n",
    "    for tracklet in range(0, data_november_29[i].shape[0]):\n",
    "        if data_november_29[i].size == 0:\n",
    "            continue\n",
    "            \n",
    "        img, true_label = tracklet_dataset[tracklet]\n",
    "        img_tensor = img.unsqueeze(0).to(device)\n",
    "        #print(true_label)\n",
    "        \n",
    "        pig_data = data_november_29[i][tracklet]\n",
    "        pig_times = load_times(200 + i) #Clips start at 200 for November 29th\n",
    "        \n",
    "        \n",
    "        pig_id = resnet_which_pig(img_tensor, resnet_model)\n",
    "\n",
    "        #frame_data = pig_data[0]\n",
    "        #x1, y1, x2, y2 = int(frame_data[1]), int(frame_data[2]), int(frame_data[3]), int(frame_data[4])\n",
    "        #crop = frames[0][y1:y2, x1:x2]\n",
    "        #cv2.imshow('Image with Bounding Box', crop)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        for frame_data in pig_data:\n",
    "            if is_eating(frame_data[13]) and at_feeder(frame_data[12]):\n",
    "                \n",
    "                if pig_id == -1:\n",
    "                    pigs_feeding_times[tracklet % 8].append(pig_times[int(frame_data[0])])\n",
    "                else:\n",
    "                    pigs_feeding_times[pig_id].append(pig_times[int(frame_data[0])])\n",
    "                #pig0_feeding_times.append(pig0_times[int(frame_data[0])])\n",
    "                \n",
    "                #display_frame(frame_data, frames[int(frame_data[0])])\n",
    "                #pigs_feeding_times[which_pig(frame, frame_data, model)] = (pig0_times[int(frame_data[0])], duration)\n",
    "                #break #Commenting this out will probably result in too much memory being used, recording every single frame that has feeding behavior\n",
    "                \n",
    "                #break\n",
    "    del frames\n",
    "pigs_feeding_times = [sorted(times) for times in pigs_feeding_times] #All pigs feeding times, only one instance max per 5 minute video\n",
    "\n",
    "#for pig in range(0, len(pigs)):\n",
    "#    pigs_feeding_times[pig] = sorted(pigs_feeding_times[pig], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad714fbc-7821-495b-9738-164d492cfa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "#for i in range(1, 10):\n",
    "#    with torch.no_grad():\n",
    "        #X_tensor = torch.tensor(intervals[-(SEQ_LENGTH+i):-i]).unsqueeze(0).unsqueeze(-1)\n",
    "        #test_input = torch.tensor(intervals[-(SEQ_LENGTH+i):-i]).unsqueeze(0).unsqueeze(-1)\n",
    "predicted = model(X_test_tensor)\n",
    "        #actual = intervals[i] - intervals[i-1]\n",
    "print(predicted)\n",
    "print(y_test_tensor)\n",
    "\n",
    "predicted = model(X_train_tensor)\n",
    "print(predicted)\n",
    "print(y_train_tensor)\n",
    "        #print(f\"/n⏱️ Predicted next feeding interval: {predicted:.2f} minutes\")\n",
    "        #print(f\"/n⏱️ Actual next feeding interval: {actual:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0798c68a-c257-40ba-8850-0a502683a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "def condense_feeding(feeding_times):\n",
    "    feeding_durations = []\n",
    "    start_time = 0\n",
    "    prev_time = 0\n",
    "    for time in feeding_times:\n",
    "        if time - prev_time < 0.15: #9 seconds\n",
    "            prev_time = time\n",
    "        else:\n",
    "            feeding_durations.append((start_time, prev_time - start_time))\n",
    "            #feeding_durations = np.append(feeding_durations, (start_time, prev_time - start_time))\n",
    "            start_time = time\n",
    "            prev_time = time\n",
    "    feeding_durations.append((start_time, prev_time - start_time))\n",
    "    #feeding_durations = np.append(feeding_durations, (start_time, prev_time - start_time))\n",
    "    return feeding_durations\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47b3d6-cf7e-41dc-ab2d-dafb62cb150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(feeding_times)\n",
    "#len(feeding_times[0])\n",
    "#print(feeding_times)\n",
    "#print(pigs_feeding_times)\n",
    "len(durations)\n",
    "durations[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3cbda40e-27b5-43f5-9f78-4c27c46fb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten pigs_feeding_times data\n",
    "pigs_feeding_times_flat = []\n",
    "for i in pigs_feeding_times:\n",
    "    for j in i:\n",
    "        pigs_feeding_times_flat.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e3b72307-7ba8-46aa-95f7-ed3032296ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss = 78.0942, Test Loss = 11.5802\n",
      "Epoch 1: Train Loss = 76.9874, Test Loss = 10.8771\n",
      "Epoch 2: Train Loss = 76.0050, Test Loss = 10.1505\n",
      "Epoch 3: Train Loss = 74.9693, Test Loss = 9.2610\n",
      "Epoch 4: Train Loss = 73.6796, Test Loss = 8.1723\n",
      "Epoch 5: Train Loss = 72.0301, Test Loss = 6.8719\n",
      "Epoch 6: Train Loss = 69.9399, Test Loss = 5.5041\n",
      "Epoch 7: Train Loss = 67.4884, Test Loss = 4.4341\n",
      "Epoch 8: Train Loss = 65.0064, Test Loss = 4.3040\n",
      "Epoch 9: Train Loss = 63.1286, Test Loss = 5.9083\n",
      "Epoch 10: Train Loss = 62.7324, Test Loss = 8.8228\n",
      "Epoch 11: Train Loss = 63.8470, Test Loss = 10.4763\n",
      "Epoch 12: Train Loss = 64.5826, Test Loss = 10.0984\n",
      "Epoch 13: Train Loss = 64.1135, Test Loss = 8.5449\n",
      "Epoch 14: Train Loss = 63.0014, Test Loss = 6.7537\n",
      "Epoch 15: Train Loss = 61.9330, Test Loss = 5.2930\n",
      "Epoch 16: Train Loss = 61.2901, Test Loss = 4.3558\n",
      "Epoch 17: Train Loss = 61.1078, Test Loss = 3.8641\n",
      "Epoch 18: Train Loss = 61.1987, Test Loss = 3.6447\n",
      "Epoch 19: Train Loss = 61.3221, Test Loss = 3.5465\n",
      "Epoch 39: Train Loss = 52.7258, Test Loss = 7.3822\n",
      "Epoch 59: Train Loss = 39.6342, Test Loss = 9.7745\n",
      "Epoch 79: Train Loss = 22.7804, Test Loss = 14.2836\n",
      "Epoch 99: Train Loss = 6.0763, Test Loss = 7.7263\n",
      "\n",
      "⏱️ Predicted next feeding start time: 23.53 minutes since start\n",
      "⏱️ Actual next feeding time: 0.65 minutes since start\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "#Pretty much the RFID tag feeding prediction\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "feeding_times = pigs_feeding_times[0]  # Choose pig 0 or any specific pig\n",
    "\n",
    "#feeding_times = sorted(pigs_feeding_times_flat) #To just get all feeding times for all pigs\n",
    "intervals = np.array([t.timestamp() - feeding_times[0].timestamp() for t in feeding_times], dtype=np.float32) / 60\n",
    "\n",
    "\n",
    "durations = condense_feeding(intervals)\n",
    "#durations = rfid_tags_durations #Use fake RFID tag data instead (run at bottom first)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x_seq = data[i:i+seq_length]  # List of tuples\n",
    "        last_start_time = x_seq[-1][0]\n",
    "\n",
    "        # Subtract last start time from all start times in the sequence\n",
    "        adjusted_seq = [(last_start_time - start_time, duration) for (start_time, duration) in x_seq]\n",
    "        xs.append(adjusted_seq)\n",
    "\n",
    "        # Compute the target delta between next and last start time\n",
    "        next_start_time = data[i + seq_length][0]\n",
    "        delta = next_start_time - last_start_time\n",
    "        ys.append(delta)\n",
    "\n",
    "    return np.array(xs, dtype=np.float32), np.array(ys, dtype=np.float32)\n",
    "\n",
    "\n",
    "SEQ_LENGTH = 5\n",
    "X, y = create_sequences(durations, SEQ_LENGTH)\n",
    "\n",
    "permutation = np.random.permutation(len(X))\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "\n",
    "#X_train_tensor = torch.tensor(X_train).unsqueeze(-1)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train).unsqueeze(-1)\n",
    "#X_test_tensor = torch.tensor(X_test).unsqueeze(-1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_test_tensor = torch.tensor(y_test).unsqueeze(-1)\n",
    "#X_tensor = torch.tensor(X).unsqueeze(-1)  # shape: (batch, seq, 1)\n",
    "#y_tensor = torch.tensor(y).unsqueeze(-1)\n",
    "\n",
    "\n",
    "class FeedLSTM(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_size=64):\n",
    "        super(FeedLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]           \n",
    "        out = self.relu(self.fc1(out))  \n",
    "        out = self.fc2(out)     \n",
    "        return out\n",
    "\n",
    "model = FeedLSTM()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "TestLoss_tolerance = 0.05\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = loss_fn(output, y_train_tensor)\n",
    "    #print(output, y_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0 or epoch < 20:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_output = model(X_test_tensor)\n",
    "            test_loss = loss_fn(test_output, y_test_tensor)\n",
    "        print(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Test Loss = {test_loss.item():.4f}\")\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    recent_sequence = np.array(durations[-SEQ_LENGTH:], dtype=np.float32)\n",
    "    test_input = torch.tensor([recent_sequence])  # shape: (1, SEQ_LENGTH, 2)\n",
    "    predicted_start_time = model(test_input).item()\n",
    "    actual_start_time = durations[-1][0] - durations[-2][0]  # last known start time\n",
    "\n",
    "    print(f\"\\n⏱️ Predicted next feeding start time: {predicted_start_time:.2f} minutes since start\")\n",
    "    print(f\"⏱️ Actual next feeding time: {actual_start_time:.2f} minutes since start\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8555c52a-8403-43ee-9178-688b97e77708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:4.26 Actual:6.81\n",
      "Predicted:1.52 Actual:0.33\n",
      "Predicted:1.58 Actual:0.57\n",
      "Predicted:1.07 Actual:4.83\n",
      "Predicted:1.21 Actual:6.76\n",
      "Predicted:1.0 Actual:1.08\n",
      "Predicted:1.45 Actual:1.66\n",
      "Predicted:0.58 Actual:0.3\n",
      "Predicted:1.15 Actual:2.17\n",
      "Predicted:1.1 Actual:0.72\n",
      "Predicted:1.28 Actual:1.54\n",
      "Predicted:2.09 Actual:3.97\n",
      "Predicted:1.79 Actual:0.47\n",
      "Predicted:1.47 Actual:2.63\n",
      "Predicted:1.05 Actual:0.42\n",
      "Predicted:1.28 Actual:0.16\n",
      "Predicted:7.13 Actual:3.63\n",
      "Predicted:1.47 Actual:5.14\n",
      "Predicted:1.11 Actual:1.4\n",
      "Predicted:9.65 Actual:1.85\n",
      "Predicted:9.24 Actual:2.08\n",
      "Predicted:7.27 Actual:5.21\n",
      "Predicted:1.03 Actual:0.59\n",
      "Predicted:1.33 Actual:2.34\n",
      "Predicted:3.49 Actual:1.15\n",
      "Predicted:2.55 Actual:1.65\n",
      "Predicted:2.01 Actual:0.46\n",
      "Predicted:1.46 Actual:2.04\n",
      "Predicted:2.4 Actual:6.46\n",
      "Predicted:1.21 Actual:2.49\n",
      "Predicted:1.76 Actual:1.8\n",
      "Predicted:16.26 Actual:6.86\n",
      "Predicted:0.99 Actual:0.61\n",
      "Predicted:0.96 Actual:0.96\n",
      "Predicted:3.08 Actual:2.22\n",
      "Predicted:1.08 Actual:0.6\n",
      "Predicted:3.16 Actual:6.81\n",
      "Predicted:2.99 Actual:3.37\n",
      "Predicted:1.46 Actual:0.37\n",
      "Predicted:6.17 Actual:6.77\n",
      "Predicted:1.57 Actual:0.92\n",
      "Predicted:1.4 Actual:1.99\n",
      "Predicted:1.2 Actual:1.58\n",
      "Predicted:6.12 Actual:6.79\n"
     ]
    }
   ],
   "source": [
    "#Just display some of the test results\n",
    "for i in range(0, len(X_test_tensor)):\n",
    "    input_tensor = X_test_tensor[i].unsqueeze(0)  # Shape: [1, N]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_output = model(input_tensor)\n",
    "        test_loss = loss_fn(test_output, y_test_tensor[0])\n",
    "    #print(f\"Epoch {epoch}: Train Loss = {loss.item():.4f}, Test Loss = {test_loss.item():.4f}\")\n",
    "    print(\"Predicted:\" + str(round(test_output.item(), 2)) + \" Actual:\" + str(round(y_test_tensor[i].item(), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "78979dc8-ef12-4e8d-a8c6-676ed05373da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏰ 0.00-time — Duration: 0.30minutes\n",
      "⏰ 0.30-time — Duration: 8.42minutes\n",
      "⏰ 8.87-time — Duration: 9.89minutes\n",
      "⏰ 23.07-time — Duration: 2.27minutes\n",
      "⏰ 33.17-time — Duration: 4.25minutes\n",
      "⏰ 44.02-time — Duration: 2.34minutes\n",
      "⏰ 53.39-time — Duration: 8.20minutes\n",
      "⏰ 66.72-time — Duration: 4.89minutes\n",
      "⏰ 78.00-time — Duration: 4.21minutes\n",
      "⏰ 88.83-time — Duration: 9.26minutes\n",
      "⏰ 104.34-time — Duration: 9.22minutes\n",
      "⏰ 122.46-time — Duration: 2.98minutes\n",
      "⏰ 135.17-time — Duration: 4.33minutes\n",
      "⏰ 147.22-time — Duration: 2.86minutes\n",
      "⏰ 157.39-time — Duration: 8.39minutes\n",
      "⏰ 171.24-time — Duration: 2.51minutes\n",
      "⏰ 180.57-time — Duration: 6.24minutes\n",
      "⏰ 192.44-time — Duration: 6.67minutes\n",
      "⏰ 205.73-time — Duration: 6.43minutes\n",
      "⏰ 219.88-time — Duration: 5.76minutes\n",
      "⏰ 233.14-time — Duration: 2.11minutes\n",
      "⏰ 243.18-time — Duration: 8.82minutes\n",
      "⏰ 257.92-time — Duration: 9.13minutes\n",
      "⏰ 274.88-time — Duration: 9.04minutes\n",
      "⏰ 293.11-time — Duration: 3.17minutes\n",
      "⏰ 306.47-time — Duration: 4.76minutes\n",
      "⏰ 319.87-time — Duration: 7.77minutes\n",
      "⏰ 335.16-time — Duration: 7.69minutes\n",
      "⏰ 350.92-time — Duration: 6.63minutes\n",
      "⏰ 365.81-time — Duration: 4.56minutes\n"
     ]
    }
   ],
   "source": [
    "#Generate fake RFID tag data\n",
    "import random\n",
    "import math\n",
    "\n",
    "rfid_tags_durations = [(0, 0.3)]\n",
    "for i in range(1, 1000):\n",
    "    # Start with last feeding time\n",
    "    next_time = rfid_tags_durations[-1][0]\n",
    "    \n",
    "    # Add decayed influence from recent durations\n",
    "    for j in range(min(len(rfid_tags_durations), 5)):\n",
    "        past_time, past_duration = rfid_tags_durations[-j - 1]\n",
    "        decay_factor = 1 / (j + 1)  # more recent = higher weight\n",
    "        next_time += past_duration * decay_factor\n",
    "\n",
    "    # Random duration\n",
    "    duration = random.uniform(2, 10)\n",
    "\n",
    "    rfid_tags_durations.append((next_time, duration))\n",
    "\n",
    "# Show first few entries\n",
    "for t, d in rfid_tags_durations[:30]:\n",
    "    print(f\"⏰ {t:.2f}-time — Duration: {d:.2f}minutes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b4aaf425-6252-4c78-8fa0-b7ffe097f7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.3)\n",
      "(0.3, 8.42454766858923)\n",
      "(8.874547668589232, 9.885469130103509)\n",
      "(23.072290632987354, 2.272228129176283)\n",
      "(33.170435883411805, 4.248011887009296)\n",
      "(44.01585512885773, 2.3407795930747497)\n",
      "(53.394326858072944, 8.19801854477652)\n",
      "(66.72389002003804, 4.885154864656367)\n",
      "(78.0047626190285, 4.211667460583982)\n",
      "(88.82647763587005, 9.262607067144419)\n",
      "(104.340963943001, 9.221796084054521)\n",
      "(122.45884513927513, 2.980075693888324)\n",
      "(135.1673024023161, 4.3258881044370705)\n",
      "(147.2151456406184, 2.8621519857098257)\n",
      "(157.39157067761872, 8.385872239003131)\n",
      "(171.23985975123878, 2.5054136106978095)\n",
      "(180.56974730822836, 6.2372660111645715)\n",
      "(192.43572648839108, 6.673401526691266)\n",
      "(205.73179734779, 6.429733670322423)\n",
      "(219.88084830232137, 5.757587837690695)\n",
      "(233.13816937566773, 2.108340056103577)\n",
      "(243.18435149129652, 8.818512119050306)\n",
      "(257.9183433072144, 9.125786145349515)\n",
      "(274.88150922427747, 9.044103165567211)\n",
      "(293.10661208376683, 3.170118455218299)\n",
      "(306.4670068778686, 4.757883877723007)\n",
      "(319.86979999853725, 7.769034929038735)\n",
      "(335.1606660386387, 7.690381321933429)\n",
      "(350.92287636458383, 6.625720782295726)\n",
      "(365.80696077800025, 4.561482204079434)\n",
      "(379.1385993216763, 3.7991510785170703)\n",
      "(390.9034674126228, 6.045134352996772)\n",
      "(403.5631778328652, 6.721804403927485)\n",
      "(417.0394478136092, 4.836073336634032)\n",
      "(429.1135523469844, 8.815136074850678)\n",
      "(444.8584403620805, 5.130956845151878)\n",
      "(458.8984676617837, 9.469692539075016)\n",
      "(476.4253965299955, 8.445720825709326)\n",
      "(494.4872812596658, 8.996166546960218)\n",
      "(513.9086388254306, 8.158980456186374)\n",
      "(532.7745573341325, 6.213966669836451)\n",
      "(550.0721051286246, 5.461260719118527)\n",
      "(565.2981951366054, 9.8954952859849)\n",
      "(583.8346214288671, 4.851029367867958)\n",
      "(598.6391064381299, 5.342402571930066)\n",
      "(612.3136306364025, 4.113613989785641)\n",
      "(624.2815816667625, 3.5851601040542462)\n",
      "(634.8962060221835, 5.395298270764626)\n",
      "(645.7610955247933, 3.1362212854974763)\n",
      "(654.8869033255237, 8.902482799606052)\n",
      "(668.8749423487708, 9.459435865358465)\n",
      "(685.8968832976002, 7.493652501705019)\n",
      "(702.9508629740471, 2.1179280422482254)\n",
      "(714.8216275126017, 3.0611158344608747)\n",
      "(725.5849470616826, 6.451067694418834)\n",
      "(738.0378489859125, 7.744948696348097)\n",
      "(752.0569159851934, 2.597934895678943)\n",
      "(761.8665456942509, 5.505136270332694)\n",
      "(773.4772890683693, 2.493349936636509)\n",
      "(782.8156361517026, 5.136819481721329)\n",
      "(793.2326494883758, 8.03396609896927)\n",
      "(806.5620130204702, 4.6427611593219)\n",
      "(818.6583951280763, 2.6979144653021967)\n",
      "(828.1385537304536, 3.859115213647339)\n",
      "(837.9300686509459, 4.008204107516135)\n",
      "(847.5346186966774, 9.515803483898067)\n",
      "(861.9439268204059, 7.26833082065988)\n",
      "(876.8105891153258, 7.30703650534529)\n",
      "(892.6975995952422, 7.7756530299795905)\n",
      "(909.7301395105922, 9.528005360013001)\n",
      "(929.3018936226547, 3.1609572608737633)\n",
      "(943.0991631973297, 5.795161067144698)\n",
      "(957.0561252401462, 6.842533947860549)\n",
      "(971.7870240878696, 3.817673289981405)\n",
      "(983.6535250947171, 8.169130490490458)\n",
      "(998.0933185984462, 4.67217214250251)\n",
      "(1010.9922794499151, 9.972597450213858)\n",
      "(1028.3469315802777, 4.757101432124677)\n",
      "(1042.453539732296, 6.33881174317787)\n",
      "(1057.2969704753311, 3.882010983903358)\n",
      "(1069.3616715992523, 4.6682992140219985)\n",
      "(1081.267708401026, 9.838518283900843)\n",
      "(1097.2705031754583, 9.393907538326339)\n",
      "(1115.378034688354, 6.586981698757367)\n",
      "(1131.8849532511947, 6.062467574525805)\n",
      "(1147.7655036016542, 2.665682292584581)\n",
      "(1159.9742607891158, 7.469461361200934)\n",
      "(1174.3229127538054, 8.251621276114921)\n",
      "(1190.0308387080986, 2.4961311332078573)\n",
      "(1201.0215150211488, 7.6783466770550435)\n",
      "(1215.0989694889965, 8.459346812390208)\n",
      "(1231.786330942252, 9.292779639742552)\n",
      "(1250.1425899190665, 7.763343035696083)\n",
      "(1267.790917941336, 7.895612036068421)\n",
      "(1286.3163007470084, 6.780357047577598)\n",
      "(1303.6473090969325, 6.486576125598006)\n",
      "(1319.9553261118815, 6.292059321623956)\n",
      "(1335.2773641283197, 3.40626283269882)\n",
      "(1347.2660603328047, 6.121670420382576)\n",
      "(1360.1659307176596, 4.955492552767542)\n",
      "(1372.1880094803769, 5.604158356224043)\n",
      "(1384.4204484922786, 3.7119611339390364)\n",
      "(1394.7979898268877, 6.750579932225171)\n",
      "(1407.7358103337588, 9.841477396314716)\n",
      "(1424.5820361737751, 5.124895737521275)\n",
      "(1438.926685874925, 9.86568599117886)\n",
      "(1457.065349410147, 3.52469580642474)\n",
      "(1471.0416721268587, 5.155553063438767)\n",
      "(1484.4976545042125, 6.851784103972401)\n",
      "(1498.5935143873448, 3.1793041322436)\n",
      "(1509.7715394092293, 6.460914081863055)\n",
      "(1522.0998610190163, 6.021224452431243)\n",
      "(1535.155367195141, 4.11931882399652)\n",
      "(1546.6041191264965, 6.302616128949249)\n",
      "(1559.2245588318353, 7.578050799231259)\n",
      "(1574.1245128996873, 2.719547594118912)\n",
      "(1584.9680325328904, 4.705530232214118)\n",
      "(1595.9588712922778, 5.2369497717189395)\n",
      "(1607.6101379704078, 8.515923803089034)\n",
      "(1622.508543795137, 8.207299800332937)\n",
      "(1638.4397474977982, 3.376466301973668)\n",
      "(1651.0088484570074, 3.3248371460424737)\n",
      "(1661.9340562592638, 7.320984795116333)\n",
      "(1675.7979581054274, 3.154294945428438)\n",
      "(1686.2066010326548, 5.2362464322509386)\n",
      "(1696.966825749564, 4.869272362012651)\n",
      "(1708.0008666041658, 2.4159728971468413)\n",
      "(1716.8496618551162, 9.615721555319642)\n",
      "(1731.2363812434953, 3.4925921623809115)\n",
      "(1742.6067258595383, 2.615780569104091)\n",
      "(1751.751890724962, 6.094358416970706)\n",
      "(1763.2054617822043, 3.8935218065655413)\n",
      "(1773.8143820052824, 9.026382787491261)\n",
      "(1788.1714420764654, 7.769893204209746)\n",
      "(1803.7991129946727, 5.930668131876995)\n",
      "(1818.815774126187, 2.750794680651241)\n",
      "(1830.1571673323663, 7.886668363018843)\n",
      "(1845.1438722715536, 6.997414314501767)\n",
      "(1860.0381980015932, 7.2506933499841555)\n",
      "(1875.2903202597058, 3.8924422144631254)\n",
      "(1887.6624066142128, 9.095343658676065)\n",
      "(1904.4475564146778, 3.3779042515757345)\n",
      "(1916.8827694341423, 4.744663953578234)\n",
      "(1928.77141595668, 2.4149072766006725)\n",
      "(1937.73694765149, 9.817020131274012)\n",
      "(1953.0065208668864, 4.332984598880416)\n",
      "(1964.9147314623137, 9.856286491939034)\n",
      "(1981.7625099073168, 2.0981514566694583)\n",
      "(1993.1703692977214, 4.875239969378264)\n",
      "(2005.4267640020555, 7.937663403403456)\n",
      "(2019.8320997517985, 5.09085885627718)\n",
      "(2033.0126654621254, 4.247401502486535)\n",
      "(2044.0898244775635, 8.39277809963306)\n",
      "(2059.262720125259, 7.4864217363371095)\n",
      "(2075.2215788069916, 9.633272123263495)\n",
      "(2093.4756766451787, 8.74158057001608)\n",
      "(2112.4770420143445, 5.6618677445803804)\n",
      "(2129.270951805698, 7.946829531845762)\n",
      "(2146.8681777779225, 3.490901687829064)\n",
      "(2160.3318330470247, 3.497984436186364)\n",
      "(2171.387994554556, 2.5786647063652133)\n",
      "(2179.998366306834, 9.47496089289903)\n",
      "(2194.3907456933043, 9.983328745152345)\n",
      "(2211.54378623364, 5.922962773171875)\n",
      "(2226.9609967408496, 9.054321784212387)\n",
      "(2245.18904932453, 6.806856782847031)\n",
      "(2262.8882122887417, 8.44637247872582)\n",
      "(2281.233526862618, 9.165437267263215)\n",
      "(2300.339275630881, 4.406611513100753)\n",
      "(2315.656641823076, 8.274604063755865)\n",
      "(2332.662661875387, 2.620950403920695)\n",
      "(2344.8704186281134, 9.103000654420988)\n",
      "(2360.976836170808, 9.000705893412755)\n",
      "(2378.3526658446303, 7.735684575307492)\n",
      "(2395.933195331849, 5.109200576826166)\n",
      "(2410.7104137385227, 6.1264860145053985)\n",
      "(2426.0408381707807, 6.033382774951189)\n",
      "(2440.5745931344363, 2.245461398320165)\n",
      "(2450.7033449843348, 5.62859926276303)\n",
      "(2462.0192641569, 6.107633836004112)\n",
      "(2474.4233276536975, 3.65835192612733)\n",
      "(2484.7797381566515, 5.394387791565015)\n",
      "(2495.8954219519696, 5.050981188340058)\n",
      "(2507.515675989688, 3.537141298771883)\n",
      "(2517.512551895218, 4.257061589588584)\n",
      "(2527.302111863422, 5.331735439540043)\n",
      "(2538.2830480527446, 2.3370919297771433)\n",
      "(2546.5995097945156, 9.359470726888034)\n",
      "(2560.6764652899574, 6.886624725371001)\n",
      "(2575.2062021998336, 9.89084144571217)\n",
      "(2593.310799654213, 7.766025525738978)\n",
      "(2611.1250735456088, 9.133891730082674)\n",
      "(2631.032475513852, 6.133858304271928)\n",
      "(2648.1719901649144, 2.9613507080644954)\n",
      "(2661.164575272386, 2.4773475059211343)\n",
      "(2671.003895604765, 9.24125833936236)\n",
      "(2685.831187521861, 9.946760038538795)\n",
      "(2703.1914685699253, 7.904336059979097)\n",
      "(2720.361211113721, 4.305435848102218)\n",
      "(2734.74018575735, 3.2996648427336215)\n",
      "(2747.1622888883016, 8.748576801283054)\n",
      "(2762.9612794163545, 5.633267044079103)\n",
      "(2776.7259493160077, 5.792206578309634)\n",
      "(2789.936985063755, 4.559410240679078)\n",
      "(2802.117331443816, 6.853441795673823)\n",
      "(2816.339246007209, 8.174605577665528)\n",
      "(2832.0350809496645, 9.5265081024828)\n",
      "(2850.2316663153697, 9.970811819047036)\n",
      "(2870.315843208601, 3.964885280602285)\n",
      "(2885.855976853106, 4.8460694559880855)\n",
      "(2900.024641030231, 2.5360824797920714)\n",
      "(2910.703391240143, 2.0166901043196708)\n",
      "(2918.588862753648, 7.456559205423491)\n",
      "(2929.903622257946, 8.485391547213121)\n",
      "(2944.39275795379, 2.6704484193874247)\n",
      "(2954.8028109039633, 2.577987251007407)\n",
      "(2963.8119640359555, 5.243530811118781)\n",
      "(2974.847297673595, 5.630792435566696)\n",
      "(2986.3238750126798, 6.763273676329416)\n",
      "(2998.828975007128, 4.21243460249473)\n",
      "(3010.126457412624, 8.614543138411554)\n",
      "(3025.558046682175, 8.49915211708785)\n",
      "(3042.585592142162, 5.582041129813957)\n",
      "(3057.69448709588, 2.933462424519286)\n",
      "(3069.248143496104, 3.1805707137351122)\n",
      "(3079.6038224556582, 5.495026514220298)\n",
      "(3090.76229584079, 6.952338079947503)\n",
      "(3103.372111247852, 2.0949309457890095)\n",
      "(3112.1567219016924, 5.642022849868485)\n",
      "(3123.1735270224067, 8.150024717705357)\n",
      "(3137.67996330314, 4.3296655158962585)\n",
      "(3149.879515813615, 7.891719106711914)\n",
      "(3164.482234485802, 7.055274926598618)\n",
      "(3180.092501553788, 6.9029995013875745)\n",
      "(3195.866132876561, 9.318410588232798)\n",
      "(3213.826664404211, 4.351084509487857)\n",
      "(3228.4801165946033, 8.242405598963897)\n",
      "(3245.1410061717224, 4.512115806546796)\n",
      "(3258.9348888282493, 2.6206747795239984)\n",
      "(3269.510543289053, 6.051973982484596)\n",
      "(3281.3077115651204, 7.867879701727942)\n",
      "(3295.8516465893617, 4.342518813256514)\n",
      "(3307.703021770501, 9.622451273130089)\n",
      "(3324.156487469028, 9.650788674476079)\n",
      "(3343.2433727730836, 8.747861147608443)\n",
      "(3362.6833176593, 3.5302474901209724)\n",
      "(3377.0785418623177, 4.676437935529792)\n",
      "(3390.773244682023, 3.556725665807609)\n",
      "(3401.9620615007666, 7.821730642998194)\n",
      "(3415.7531017238975, 3.4911718550447306)\n",
      "(3426.2158731042837, 7.51400719572625)\n",
      "(3439.907178778756, 6.362080714813454)\n",
      "(3453.856764837026, 5.964834661339539)\n",
      "(3467.9444480133748, 8.52950464137896)\n",
      "(3484.1537997269684, 9.51874235483966)\n",
      "(3503.018894240792, 9.208228131194147)\n",
      "(3522.5932865714967, 8.444624469727627)\n",
      "(3542.1402823177145, 5.493993344864322)\n",
      "(3559.011583791493, 5.980323412706779)\n",
      "(3574.7595842036408, 8.936271321806348)\n",
      "(3592.4701500904266, 4.879741005932296)\n",
      "(3606.8738911249925, 7.616659604048183)\n",
      "(3622.503057861425, 4.99213941655779)\n",
      "(3636.360239928311, 4.623167142147353)\n",
      "(3649.025552829264, 7.280372734470913)\n",
      "(3663.161668709193, 8.885021944626876)\n",
      "(3679.999299510053, 4.0311152367126555)\n",
      "(3693.0539362994173, 5.076012697127955)\n",
      "(3705.8519072084914, 9.731685190397709)\n",
      "(3723.1426338594088, 8.291717671290932)\n",
      "(3740.776981556378, 6.648964570587083)\n",
      "(3756.8909262477005, 9.097907722116911)\n",
      "(3775.525345982566, 4.697229421913072)\n",
      "(3791.007117244969, 5.768296715295213)\n",
      "(3805.477249255498, 6.64468912584234)\n",
      "(3820.176099724272, 9.880629466070971)\n",
      "(3838.29572822493, 7.262215567409968)\n",
      "(3855.0946749638624, 3.364787858493517)\n",
      "(3868.1989453859373, 8.482790483442102)\n",
      "(3884.5839635127822, 6.512353458493019)\n",
      "(3900.2509879508943, 5.297867107315721)\n",
      "(3913.9262686933757, 6.07603154788675)\n",
      "(3927.615673473644, 8.42662689779073)\n",
      "(3944.1709183091284, 5.457996470964574)\n",
      "(3958.4945095468115, 3.7632409286376625)\n",
      "(3970.374205651963, 6.575563003396136)\n",
      "(3983.972584310691, 2.3260530195440454)\n",
      "(3993.8906569721116, 2.3711742706808803)\n",
      "(4001.6491216133822, 5.333480386257451)\n",
      "(4011.3400790780715, 7.413143571416083)\n",
      "(4024.106980121742, 4.302585814301186)\n",
      "(4034.951968688749, 5.849368394611746)\n",
      "(4047.2312827983505, 6.704026160559557)\n",
      "(4061.2141703977545, 4.3541109250367)\n",
      "(4073.4283590358004, 2.5211048000834326)\n",
      "(4082.6840539467685, 5.164745520017832)\n",
      "(4093.406602394236, 4.246135220280819)\n",
      "(4103.504811604592, 9.16420630585305)\n",
      "(4118.01476574562, 2.2803726909105357)\n",
      "(4128.088027336239, 6.172264876014673)\n",
      "(4140.549696902068, 6.7295075851074335)\n",
      "(4154.265739776006, 6.023311985692492)\n",
      "(4168.114161613488, 3.34371774333016)\n",
      "(4178.711845301887, 8.670471242866466)\n",
      "(4193.978775949795, 7.154063499561426)\n",
      "(4209.434377165345, 8.766256166022124)\n",
      "(4226.708413995074, 4.573271146605589)\n",
      "(4240.885862417259, 2.4045773511719544)\n",
      "(4252.021770853871, 2.3546697603455575)\n",
      "(4260.725529746755, 8.279525503622244)\n",
      "(4273.8804849341295, 6.754137913315584)\n",
      "(4287.075074086485, 9.520854453628449)\n",
      "(4303.8024222416325, 5.122958715779774)\n",
      "(4318.478002816639, 8.788719918503006)\n",
      "(4336.3462598232945, 8.865097251766299)\n",
      "(4355.044411135643, 8.993787508012586)\n",
      "(4374.585231145376, 9.870176341546141)\n",
      "(4395.1291053809655, 4.978784607234186)\n",
      "(4412.014925624952, 6.416039190352074)\n",
      "(4428.2318822267935, 4.886229457627695)\n",
      "(4442.252027735663, 2.5373035880187924)\n",
      "(4452.589857202732, 5.989277160873473)\n",
      "(4464.076296029192, 9.490360803922812)\n",
      "(4479.911828478703, 5.094992109682922)\n",
      "(4493.359998499168, 3.126118489538845)\n",
      "(4504.201846652679, 6.327944033256047)\n",
      "(4517.3616262670885, 7.924124407367234)\n",
      "(4532.663582375802, 2.94713659789166)\n",
      "(4543.482623899451, 8.06646566502669)\n",
      "(4557.871242372102, 4.803685460478335)\n",
      "(4570.93715943955, 4.631403989348094)\n",
      "(4582.980837078426, 7.077045805724864)\n",
      "(4596.580857101485, 2.2440790576238534)\n",
      "(4606.72147488988, 8.422020852805112)\n",
      "(4620.743138629504, 3.3664528218887817)\n",
      "(4631.764170479637, 8.15115502073175)\n",
      "(4646.382321121133, 3.0061007495823118)\n",
      "(4657.140471346437, 7.757174912421388)\n",
      "(4671.64376568326, 6.074739553254508)\n",
      "(4685.3102055954805, 8.6808085926782)\n",
      "(4701.9958651271345, 2.1559963550398944)\n",
      "(4713.057692840954, 8.523774340330124)\n",
      "(4728.6231880938285, 3.647188346649746)\n",
      "(4740.636079121145, 5.839511363017577)\n",
      "(4753.415603578225, 9.08528329733083)\n",
      "(4769.198514862039, 6.301486034547501)\n",
      "(4784.605698287653, 9.594589034858078)\n",
      "(4802.568773615646, 7.079700213944199)\n",
      "(4819.985486788805, 2.0823153023764043)\n",
      "(4832.1982767112095, 3.206236741068027)\n",
      "(4842.464515640405, 8.690207302899676)\n",
      "(4857.1407892750885, 7.8169047086454615)\n",
      "(4872.308062083924, 2.2414110377142924)\n",
      "(4882.572683489336, 3.127462386764387)\n",
      "(4892.240285471778, 2.277576548577324)\n",
      "(4900.5209978640505, 2.106845549958404)\n",
      "(4906.93285285171, 6.3208378702908234)\n",
      "(4916.296453484073, 3.8574507740070167)\n",
      "(4925.211491657709, 6.525541522151386)\n",
      "(4936.754931220833, 2.217169226502036)\n",
      "(4945.522266710644, 2.7459138571456014)\n",
      "(4953.780475955984, 8.635446584877059)\n",
      "(4966.9308114136065, 6.832338128988198)\n",
      "(4980.855578065138, 3.934646612830763)\n",
      "(4992.214788247009, 8.243495662139855)\n",
      "(5007.4110976762095, 9.704010987768296)\n",
      "(5025.9835792152135, 6.362162424691297)\n",
      "(5042.295708300175, 8.246071653306297)\n",
      "(5059.805334733183, 2.8024833245521057)\n",
      "(5072.926276571989, 5.062386908892551)\n",
      "(5085.669938497986, 8.29420677648831)\n",
      "(5100.7634502353685, 9.485476944138895)\n",
      "(5118.433328032515, 2.03779013213202)\n",
      "(5129.804685621013, 7.6895195218396415)\n",
      "(5144.760954932865, 4.583982194955735)\n",
      "(5157.89917085745, 5.11466631556623)\n",
      "(5170.275544366302, 7.760012137756091)\n",
      "(5184.450821633713, 2.692316080705429)\n",
      "(5195.411932008259, 8.386044238500915)\n",
      "(5209.926268017581, 8.826793567358429)\n",
      "(5226.8064586953105, 9.15241627123429)\n",
      "(5245.392701277451, 8.588666768912258)\n",
      "(5264.1348149802, 2.3847978248856263)\n",
      "(5277.748658852825, 6.423358056915199)\n",
      "(5292.280767526434, 6.033243527596241)\n",
      "(5306.2982726372575, 5.730658975496195)\n",
      "(5319.50060553886, 4.454441784721195)\n",
      "(5330.9142570664, 3.6456072742786017)\n",
      "(5341.49028738482, 8.941592068364269)\n",
      "(5356.378810467956, 5.423556899565989)\n",
      "(5369.7481080677435, 9.307056526163942)\n",
      "(5386.54976390866, 3.9148064368513165)\n",
      "(5399.8904703803955, 9.639719851063493)\n",
      "(5417.734153263836, 6.880643043968372)\n",
      "(5434.15106722374, 9.614563418884241)\n",
      "(5453.259305029409, 8.720708642177236)\n",
      "(5472.273734312487, 3.6988882975737774)\n",
      "(5487.185936135315, 6.740433868843475)\n",
      "(5502.462486497187, 7.145987730043607)\n",
      "(5518.314743771832, 9.285779148673736)\n",
      "(5536.089191877972, 9.497061934362474)\n",
      "(5555.03602542341, 7.867422242585391)\n",
      "(5573.881822055681, 6.349583641338409)\n",
      "(5591.081446462945, 4.745603685635029)\n",
      "(5605.855737363436, 4.165737596491234)\n",
      "(5618.37707263071, 4.926402816280018)\n",
      "(5630.129092499299, 3.6434728066974253)\n",
      "(5640.080663562643, 3.085459939450187)\n",
      "(5648.620549313785, 3.151237159308189)\n",
      "(5656.593755601752, 8.997116155999997)\n",
      "(5670.09112574882, 6.910123914301305)\n",
      "(5684.050279673759, 7.3013161607742685)\n",
      "(5699.210597788068, 7.518955084545911)\n",
      "(5715.563112061964, 2.2625725281855003)\n",
      "(5727.545888395789, 3.384998713431438)\n",
      "(5737.775845557882, 2.771361437782148)\n",
      "(5746.333899198399, 9.395924085919221)\n",
      "(5760.313271056643, 7.090199851695841)\n",
      "(5774.32398428122, 5.508180112164514)\n",
      "(5787.879079116671, 9.90627842515019)\n",
      "(5805.806100857505, 8.622682714617785)\n",
      "(5824.869717602194, 4.424437686256038)\n",
      "(5839.702674452523, 2.160245526494765)\n",
      "(5850.527572022405, 6.588630908641605)\n",
      "(5863.808064620064, 2.489938723716933)\n",
      "(5873.143046604755, 2.1607335572782205)\n",
      "(5880.169908745647, 3.3494891662268858)\n",
      "(5887.508951097545, 7.352297035897828)\n",
      "(5899.196448098306, 2.239591366511746)\n",
      "(5907.266855505571, 2.8660813227602917)\n",
      "(5914.973017193232, 4.1326948200967655)\n",
      "(5923.793255222432, 6.078714704435754)\n",
      "(5934.924035026645, 3.1838752678908824)\n",
      "(5943.689271190778, 4.9086923264513)\n",
      "(5953.822529355562, 7.720214204826429)\n",
      "(5967.404599119706, 7.811671010563395)\n",
      "(5982.724319766026, 2.310827550725948)\n",
      "(5993.378335692168, 2.3118922789148204)\n",
      "(6002.361324099797, 8.895163384176142)\n",
      "(6016.6796700672785, 3.0975888800270504)\n",
      "(6027.135512488825, 8.267512961697797)\n",
      "(6040.957012931804, 6.213211836819695)\n",
      "(6055.0226801779745, 3.5798403289762977)\n",
      "(6067.018393976102, 7.561255596509498)\n",
      "(6081.127036365803, 9.046981451865381)\n",
      "(6098.354731277127, 4.857600276141998)\n",
      "(6112.39384326098, 7.78195096954308)\n",
      "(6128.226536817471, 7.4342619039673865)\n",
      "(6144.944970780526, 3.547812204670617)\n",
      "(6157.827693953103, 4.126844225064847)\n",
      "(6169.1235393794395, 2.650736807482774)\n",
      "(6178.435258037579, 2.063083225583661)\n",
      "(6185.5731298405535, 9.105179184661715)\n",
      "(6198.334703071035, 4.176132084550055)\n",
      "(6209.239172203327, 6.494286878609549)\n",
      "(6221.902503020325, 6.465404002421743)\n",
      "(6235.696005931517, 6.1760426581139525)\n",
      "(6250.134581741781, 3.3154690678057355)\n",
      "(6261.15200494268, 7.257737101849526)\n",
      "(6275.041365840798, 7.706958588904667)\n",
      "(6290.319440801574, 8.420291305881712)\n",
      "(6307.076532901098, 7.621773125152341)\n",
      "(6323.954965964517, 7.048181312940614)\n",
      "(6340.999084676258, 5.135775015678521)\n",
      "(6355.846005934376, 7.875340492677427)\n",
      "(6372.228129248338, 4.547686825748592)\n",
      "(6385.711811278917, 6.2583036212440355)\n",
      "(6399.562651827101, 2.462003824924051)\n",
      "(6409.665693197535, 4.819373294459656)\n",
      "(6420.514159416511, 4.840804462541149)\n",
      "(6431.059431738385, 5.390390604881208)\n",
      "(6442.343844019836, 3.6361251430620625)\n",
      "(6451.986010041453, 4.429891570388873)\n",
      "(6462.204836826192, 4.4679442902389095)\n",
      "(6472.415527159708, 4.061199202873258)\n",
      "(6482.174438437905, 5.381225896687943)\n",
      "(6492.910276620652, 8.659363887833143)\n",
      "(6507.616950911091, 5.131352089588737)\n",
      "(6520.780615568925, 8.885641872230838)\n",
      "(6537.275934429975, 6.90788132753018)\n",
      "(6553.578173541447, 5.8700560653478435)\n",
      "(6568.8787616946, 9.480373435132393)\n",
      "(6586.8444711575585, 3.46723538726544)\n",
      "(6600.512677323834, 7.594047318760163)\n",
      "(6615.849557096448, 6.670135855503745)\n",
      "(6631.0165663122725, 2.8591152721281254)\n",
      "(6642.504982152249, 7.038818307870444)\n",
      "(6655.788695621827, 5.741635670485563)\n",
      "(6669.189122297918, 6.676403529338995)\n",
      "(6683.131422420923, 8.221575723446303)\n",
      "(6698.93660609726, 7.032989902002068)\n",
      "(6715.149024283292, 6.051754493110277)\n",
      "(6730.275226984983, 3.7395509639959528)\n",
      "(6742.7756597995985, 6.257578895842773)\n",
      "(6756.322828295332, 5.970454949052919)\n",
      "(6769.588126283982, 2.244058452178133)\n",
      "(6779.048510482256, 2.979445928579854)\n",
      "(6787.452442203367, 4.440133138633016)\n",
      "(6796.874447306782, 2.0332028485981386)\n",
      "(6803.875970970411, 7.931808050036345)\n",
      "(6815.498097996871, 9.361338314863914)\n",
      "(6831.208997089994, 2.425258108999059)\n",
      "(6842.355187712979, 3.507930927463774)\n",
      "(6852.585786382126, 4.602478143470856)\n",
      "(6863.677345547717, 6.074611624854564)\n",
      "(6875.701088743685, 9.830478029651005)\n",
      "(6891.465066320586, 6.320115322910324)\n",
      "(6906.5774969213, 6.946464882736403)\n",
      "(6922.399994010283, 7.44017983226578)\n",
      "(6939.092653223937, 3.134954903952286)\n",
      "(6951.8093107749255, 4.48506730572009)\n",
      "(6963.342554761976, 2.5063552007750323)\n",
      "(6972.3857665182095, 7.237267869755473)\n",
      "(6984.643009116033, 8.925038163509836)\n",
      "(6999.770390755233, 4.98747582530382)\n",
      "(7013.156410546881, 8.122690856311287)\n",
      "(7029.058440044608, 8.628438371665359)\n",
      "(7047.089428901026, 2.517752432847848)\n",
      "(7059.660840727504, 9.467771249308157)\n",
      "(7076.291802196264, 9.232556015973092)\n",
      "(7094.87914241202, 4.632658264101799)\n",
      "(7109.639128216423, 5.867725243187927)\n",
      "(7123.77119456255, 5.101650439900773)\n",
      "(7137.552620299267, 7.458563475964114)\n",
      "(7152.522593178797, 5.439397836964964)\n",
      "(7165.785285863996, 3.661992514949672)\n",
      "(7177.102122781363, 6.4745707989860195)\n",
      "(7190.105793407117, 9.526807138885946)\n",
      "(7206.942112271581, 4.210383508962646)\n",
      "(7220.077467312446, 7.363210832076074)\n",
      "(7235.072513481368, 3.790009452334025)\n",
      "(7247.624205463913, 6.457232113900238)\n",
      "(7261.38880321969, 8.186220974885781)\n",
      "(7276.749856145449, 9.440228427512064)\n",
      "(7294.855750294536, 2.274388758146289)\n",
      "(7306.951303510342, 3.86836545742025)\n",
      "(7318.441607822508, 6.270776338737404)\n",
      "(7331.401997777859, 9.971663839116726)\n",
      "(7348.255147813856, 9.545647160756104)\n",
      "(7366.298854789733, 4.952463111265844)\n",
      "(7381.689396603918, 7.160709850982054)\n",
      "(7398.255291624979, 6.619650191711269)\n",
      "(7414.486862337281, 9.600280755604953)\n",
      "(7432.931116682371, 5.455184628979433)\n",
      "(7448.1736618380555, 9.413903922690594)\n",
      "(7466.602306178562, 8.642562077217871)\n",
      "(7485.494215320694, 2.061664561753428)\n",
      "(7498.298981203652, 2.324282797515508)\n",
      "(7507.979463214253, 7.971268146916782)\n",
      "(7521.8435155843545, 8.362552976595676)\n",
      "(7537.210392122795, 8.742268664143525)\n",
      "(7553.784430269272, 9.160773275528832)\n",
      "(7572.561529131971, 8.08122316863712)\n",
      "(7591.822120366619, 7.990243147043654)\n",
      "(7610.76464395118, 5.8206845398575)\n",
      "(7627.312838172483, 5.856479259303954)\n",
      "(7642.595534531329, 6.32454181376253)\n",
      "(7657.4023495751835, 5.161799257630533)\n",
      "(7670.731799257169, 9.042095593576066)\n",
      "(7687.091231806945, 2.707683588546793)\n",
      "(7698.792994250125, 9.09087243879911)\n",
      "(7714.807098524883, 7.1931857532031485)\n",
      "(7730.741165443589, 9.954859409534972)\n",
      "(7749.808248558511, 6.385968480110461)\n",
      "(7766.383630155199, 4.261385921015427)\n",
      "(7780.772757712175, 7.25903568383987)\n",
      "(7796.218494519584, 3.1216105456520182)\n",
      "(7807.977548882763, 2.3738208195201747)\n",
      "(7816.674393712664, 3.9183394376415146)\n",
      "(7825.4872165137795, 4.408014095224215)\n",
      "(7834.877883707512, 5.896596403291924)\n",
      "(7845.502377618309, 8.723974995191089)\n",
      "(7860.098337870202, 8.194068904884904)\n",
      "(7876.505597818448, 8.59796263195203)\n",
      "(7894.464338487774, 3.649238796907408)\n",
      "(7908.504227931741, 3.2854907373022373)\n",
      "(7920.273637836741, 7.594431772385824)\n",
      "(7934.515532349046, 9.07593612421185)\n",
      "(7951.115750164169, 6.290568549587119)\n",
      "(7966.026984477032, 6.599564110428228)\n",
      "(7981.352850994214, 4.470768624515906)\n",
      "(7995.008128242671, 7.132751714406951)\n",
      "(8009.963948335052, 3.857840170525982)\n",
      "(8021.786425308478, 2.333196286817212)\n",
      "(8030.863730563575, 9.33440965101288)\n",
      "(8045.328026735009, 7.7835268315629325)\n",
      "(8060.947500873198, 8.435376904907944)\n",
      "(8077.740978183368, 8.873910802751135)\n",
      "(8096.227328052544, 6.565553547559193)\n",
      "(8113.854392941208, 3.239871871963322)\n",
      "(8127.000561447075, 2.489381364796631)\n",
      "(8137.203949678709, 5.0932446884424944)\n",
      "(8148.038012887644, 6.257315534694203)\n",
      "(8159.794823232327, 5.845283788019485)\n",
      "(8171.736832732767, 7.095945817848202)\n",
      "(8185.612379734594, 2.1598843050372736)\n",
      "(8195.851642699256, 8.49515240395569)\n",
      "(8210.50483658229, 8.890103654374222)\n",
      "(8227.30552108572, 7.129057334022679)\n",
      "(8243.670507954745, 6.972173410753949)\n",
      "(8259.726342879298, 5.5632691390519895)\n",
      "(8275.073607562788, 7.749900079641205)\n",
      "(8291.489485079921, 2.021177214190204)\n",
      "(8302.408890199775, 4.116726380497294)\n",
      "(8312.904757180826, 4.398869558711008)\n",
      "(8323.085844515568, 3.5070024808262215)\n",
      "(8332.219798222059, 3.2686471069762115)\n",
      "(8340.141653460314, 7.951822653990629)\n",
      "(8352.819863160512, 4.909172221581482)\n",
      "(8364.551020276695, 3.491319263304124)\n",
      "(8374.66609547503, 7.265098606807655)\n",
      "(8387.954929538908, 2.482240338192671)\n",
      "(8398.051149854467, 4.410773796263173)\n",
      "(8407.97940761557, 3.9477789718513066)\n",
      "(8417.47452543598, 2.845308308333749)\n",
      "(8425.837560968235, 5.519188450842706)\n",
      "(8435.694471413899, 6.871080639359652)\n",
      "(8448.142681883672, 2.2938594348425125)\n",
      "(8457.212693993264, 5.9825291706339305)\n",
      "(8468.581371868817, 5.885400107122119)\n",
      "(8481.044264222877, 3.570197947094095)\n",
      "(8491.499019600327, 3.6120024643180697)\n",
      "(8500.812325253528, 2.5571454099954574)\n",
      "(8509.033393738953, 4.220757230656618)\n",
      "(8517.806354004242, 8.853214128877891)\n",
      "(8531.239368757278, 5.049514856969938)\n",
      "(8543.484096600936, 8.99403293275489)\n",
      "(8559.520576728131, 6.757880301178121)\n",
      "(8575.51610009303, 8.441843357457106)\n",
      "(8593.367916118677, 9.836153476127782)\n",
      "(8612.936029245178, 2.852129722806807)\n",
      "(8627.008460153713, 7.712060583941558)\n",
      "(8642.887340324032, 5.094729528103611)\n",
      "(8656.936217092232, 3.7519738796465134)\n",
      "(8668.486505723173, 3.8439607467223054)\n",
      "(8678.403137676301, 9.687150890561522)\n",
      "(8694.079021398922, 2.4510461043709837)\n",
      "(8704.611902573011, 3.062659868115313)\n",
      "(8713.840520752776, 2.762420703899357)\n",
      "(8722.141866630842, 4.213410882792761)\n",
      "(8731.307566192494, 3.2817229383056814)\n",
      "(8738.872675661398, 9.650219580086784)\n",
      "(8752.871364154502, 2.3899190646980655)\n",
      "(8762.786137516825, 5.0972832240994945)\n",
      "(8773.958233044437, 8.18473820499255)\n",
      "(8788.557152032396, 6.50630690314201)\n",
      "(8803.38244612826, 4.896922023668903)\n",
      "(8816.013072290796, 8.461568831507034)\n",
      "(8832.157512297917, 6.873342105907726)\n",
      "(8848.157470527583, 3.7973047685200996)\n",
      "(8860.737461179438, 7.207060890898358)\n",
      "(8875.22906510251, 6.565615213756535)\n",
      "(8890.074628310667, 4.808025124298388)\n",
      "(8902.891809285456, 5.433069303891147)\n",
      "(8915.478655732511, 6.7459074798767205)\n",
      "(8929.626588887386, 3.035935390903492)\n",
      "(8940.361630443353, 6.6293732361428)\n",
      "(8953.077479552407, 3.3996547095091083)\n",
      "(8963.57689007437, 5.805697869228389)\n",
      "(8975.400371720767, 4.187027913799647)\n",
      "(8985.887997192902, 4.032293063817627)\n",
      "(8996.124825161301, 9.908846344171485)\n",
      "(9011.576849417857, 7.8226239611353146)\n",
      "(9027.905890791315, 9.29524164355591)\n",
      "(9046.260872045545, 3.8324881136168205)\n",
      "(9060.632192500125, 6.657809224460187)\n",
      "(9076.242084921696, 9.584434869388108)\n",
      "(9094.321255644303, 4.629811980463884)\n",
      "(9108.779725158061, 7.117015999160103)\n",
      "(9123.83740869942, 9.376590886043033)\n",
      "(9142.043448807437, 7.898291386737037)\n",
      "(9160.076714272574, 3.6865982076853907)\n",
      "(9173.543204864858, 7.760415077384029)\n",
      "(9189.547233763005, 6.4954673631241375)\n",
      "(9205.001665757942, 4.239506932846391)\n",
      "(9217.577019227414, 7.323498597996485)\n",
      "(9231.862850490425, 6.599684707878521)\n",
      "(9246.713403331174, 8.824664084742267)\n",
      "(9263.638046175025, 3.5418578261249865)\n",
      "(9276.470906982215, 9.341603366113748)\n",
      "(9293.639614852875, 7.146941976476429)\n",
      "(9310.164080750545, 5.819292055969622)\n",
      "(9325.321108856937, 9.48820777629276)\n",
      "(9343.145049060126, 9.582477555875201)\n",
      "(9363.066450690145, 6.1800092948638765)\n",
      "(9380.084646097665, 8.715931522577474)\n",
      "(9398.620651808234, 5.152791975101738)\n",
      "(9414.48467358714, 6.1693256543425345)\n",
      "(9429.59720357145, 4.174920264578108)\n",
      "(9441.989368727853, 8.531149753184284)\n",
      "(9457.695804796396, 2.650343313650204)\n",
      "(9468.576252883438, 5.722830086436836)\n",
      "(9480.74556640811, 8.16315809924815)\n",
      "(9495.621358813007, 2.936108522483961)\n",
      "(9506.915472192977, 5.714966413617928)\n",
      "(9518.780321751927, 7.408687039459816)\n",
      "(9533.210550381124, 7.71254514189886)\n",
      "(9548.899086597763, 9.478525294911293)\n",
      "(9566.71941011801, 5.445848776844699)\n",
      "(9582.470534965532, 5.529092078177686)\n",
      "(9597.291933557137, 5.746385885016886)\n",
      "(9611.530288758964, 8.751902659651346)\n",
      "(9628.255582307042, 7.960996313105746)\n",
      "(9644.97943468656, 9.766616878061972)\n",
      "(9664.186265494614, 5.594911856981887)\n",
      "(9680.655404070245, 9.271189494831198)\n",
      "(9699.720218063128, 2.128335078671344)\n",
      "(9712.382971990344, 5.594310586455362)\n",
      "(9725.483897954271, 7.012232871553904)\n",
      "(9739.43951089038, 8.62839757574242)\n",
      "(9755.825116766018, 4.036902255643253)\n",
      "(9768.337873429065, 3.587938211116551)\n",
      "(9779.69231562843, 8.469172696229386)\n",
      "(9794.860637483678, 5.573938978690068)\n",
      "(9808.600047293246, 8.582226955053223)\n",
      "(9824.496666306963, 5.564634230401735)\n",
      "(9839.045274490734, 7.6698760660971494)\n",
      "(9855.445529274302, 9.227710415493252)\n",
      "(9873.623400334147, 7.284470601083971)\n",
      "(9891.185955446954, 9.215238125955082)\n",
      "(9910.149728207885, 3.0140036391411105)\n",
      "(9924.040410594123, 4.502539308014559)\n",
      "(9936.788357497064, 8.327074788694791)\n",
      "(9952.132073471184, 9.236985854296552)\n",
      "(9969.62999169081, 3.3650557496666824)\n",
      "(9982.117667518687, 4.409455174871831)\n",
      "(9994.270922411933, 6.293644259371308)\n",
      "(10007.865640929942, 3.561423093754569)\n",
      "(10018.732365653283, 7.258166884719347)\n",
      "(10031.64450044832, 9.39466800845666)\n",
      "(10048.310695030206, 9.011196170763977)\n",
      "(10066.587698792084, 2.9209858684320977)\n",
      "(10079.672665088647, 3.0193516824973017)\n",
      "(10090.956542141339, 6.824172052815542)\n",
      "(10104.39578463593, 6.737616731857708)\n",
      "(10118.08442365629, 6.555660884343698)\n",
      "(10131.622652018477, 2.300813508878762)\n",
      "(10141.757081563184, 6.15696080483369)\n",
      "(10154.298908010765, 8.454382582990137)\n",
      "(10169.585147399925, 2.4069728330211486)\n",
      "(10180.157967346808, 9.600522231260783)\n",
      "(10195.779506425228, 7.378511939697854)\n",
      "(10212.105591564945, 8.525240101149084)\n",
      "(10229.812881437882, 4.972416941712311)\n",
      "(10244.388947534488, 9.591622594372076)\n",
      "(10263.073257731277, 8.412000342270801)\n",
      "(10281.545554097864, 2.6813773118583164)\n",
      "(10294.578291367972, 2.5758290206479577)\n",
      "(10304.691198195576, 6.849368535086842)\n",
      "(10317.743598282716, 9.311787349877228)\n",
      "(10333.691423970104, 6.827422014858727)\n",
      "(10348.638095222464, 7.719680800674523)\n",
      "(10365.102924085095, 7.03541844629851)\n",
      "(10381.971810814503, 7.670454013141106)\n",
      "(10399.302413958043, 7.7724907311701195)\n",
      "(10416.550675781022, 6.287243393786408)\n",
      "(10432.583773316484, 3.6625238725731863)\n",
      "(10445.305446322218, 3.0719312536061487)\n",
      "(10455.781600795459, 4.457779141500584)\n",
      "(10466.122495849302, 4.850171590883341)\n",
      "(10476.398613742373, 6.291399627735367)\n",
      "(10488.101513133966, 8.435827729191118)\n",
      "(10503.028595576749, 9.613724060092563)\n",
      "(10521.061465436704, 6.917385977204611)\n",
      "(10538.140540245462, 4.969576146922875)\n",
      "(10553.14062092553, 5.740919315123976)\n",
      "(10567.762720200712, 3.7197867097761694)\n",
      "(10579.661583256679, 3.123065547381823)\n",
      "(10589.184053162826, 8.1161015418259)\n",
      "(10602.530761439766, 5.66581996876103)\n",
      "(10615.373784569036, 8.532305397796645)\n",
      "(10630.969090860624, 3.3496862472425573)\n",
      "(10643.12717495795, 3.534719957255305)\n",
      "(10654.220515138648, 9.05097445335442)\n",
      "(10669.421651996247, 5.0654217926283645)\n",
      "(10682.734683642673, 4.519708416812952)\n",
      "(10694.357711679013, 4.182193552017241)\n",
      "(10705.457920975101, 9.817886268947397)\n",
      "(10721.950023831156, 9.479748352531558)\n",
      "(10739.875791298226, 9.863026241319217)\n",
      "(10759.700810543494, 8.660035910347192)\n",
      "(10779.743185969652, 7.649104555312119)\n",
      "(10799.343498235832, 8.05635831281366)\n",
      "(10818.47279369392, 5.670543138015303)\n",
      "(10834.85883173263, 6.871663548202812)\n",
      "(10850.895502941676, 2.468461925686862)\n",
      "(10862.233888176735, 5.603871214774865)\n",
      "(10874.39145231749, 4.794139401532066)\n",
      "(10885.662372482959, 9.83810291754249)\n",
      "(10901.75695036392, 7.945959895148176)\n",
      "(10918.114668373852, 8.922092751583506)\n",
      "(10936.608417805526, 3.8461276360210412)\n",
      "(10950.982598725415, 5.710299191463124)\n",
      "(10965.544103209379, 2.373787619444049)\n",
      "(10975.874798136821, 2.7586029091435122)\n",
      "(10984.469678378828, 6.487219113896361)\n",
      "(10995.324261812182, 8.811542841145709)\n",
      "(11010.034455256477, 3.71009635692927)\n",
      "(11021.477137656453, 2.113480111730656)\n",
      "(11030.556372254, 9.298500607064952)\n",
      "(11045.648641235639, 9.929492391157895)\n",
      "(11063.62170995837, 3.1556719029850173)\n",
      "(11076.112017558607, 4.5696250836594805)\n",
      "(11088.316630564925, 4.748832342820579)\n",
      "(11100.744239303105, 7.833976431683611)\n",
      "(11115.250656721395, 5.048352460811005)\n",
      "(11127.572482163836, 4.355720962181227)\n",
      "(11139.164837936087, 8.956373629661641)\n",
      "(11154.890116776927, 4.700021220918028)\n",
      "(11168.34911520161, 8.777257072012286)\n",
      "(11184.56044149334, 4.657609048116996)\n",
      "(11198.283590417623, 2.8508615435450677)\n",
      "(11209.355288873727, 2.4663301726466855)\n",
      "(11217.933904679705, 8.54804360463281)\n",
      "(11231.585254228276, 6.05724397237309)\n",
      "(11244.382867256023, 2.4545954597846187)\n",
      "(11253.902187422076, 8.579707482539888)\n",
      "(11268.358550894322, 9.11138346695838)\n",
      "(11285.801906303164, 6.039361000654401)\n",
      "(11301.081959190898, 8.628183694927484)\n",
      "(11318.402797171064, 2.9452892820626078)\n",
      "(11331.66908599739, 3.084914642063242)\n",
      "(11342.434823455682, 5.823990814327168)\n",
      "(11354.147952808926, 6.436128106917641)\n",
      "(11366.986340263195, 5.930753226065002)\n",
      "(11379.436774331089, 4.213836306084393)\n",
      "(11390.834343917839, 7.195461184325275)\n",
      "(11404.887471186821, 2.9404390609359066)\n",
      "(11415.600166869846, 3.950196598993556)\n",
      "(11425.658679782484, 6.14658432444806)\n",
      "(11437.402141317372, 4.495890668070251)\n",
      "(11448.46225834943, 3.4327434753801978)\n",
      "(11457.767445562262, 8.273822277631059)\n",
      "(11471.582955201184, 6.078583857688329)\n",
      "(11485.295987554722, 6.192957227586331)\n",
      "(11499.043541472822, 8.221925702752017)\n",
      "(11515.14314467308, 6.265203041112089)\n",
      "(11530.758040061379, 7.382589307586757)\n",
      "(11546.777828868871, 8.748541922338024)\n",
      "(11564.600139329912, 4.033150092822582)\n",
      "(11578.679109387262, 6.635106184182086)\n",
      "(11593.345659193752, 2.3795149327401344)\n",
      "(11604.050763924959, 2.9062686123598063)\n",
      "(11613.116487972757, 4.704172865485354)\n",
      "(11622.53237335328, 5.833807407327778)\n",
      "(11633.608923367492, 7.72861488346882)\n",
      "(11647.02496971609, 7.2998333896832985)\n",
      "(11661.891009955461, 8.29671567993599)\n",
      "(11678.813133716325, 2.2960593794010222)\n",
      "(11690.789743934587, 3.7412218215002513)\n",
      "(11701.815248663215, 5.608164918493022)\n",
      "(11713.593523216845, 3.0008500011975308)\n",
      "(11722.878887598625, 9.47425491243575)\n",
      "(11737.11747314908, 2.3052140904951575)\n",
      "(11747.310383623448, 7.500932718110104)\n",
      "(11760.993853841615, 7.743367143822597)\n",
      "(11776.224825769674, 2.99383161896668)\n",
      "(11788.061806371701, 3.8397075612744125)\n",
      "(11798.315828121358, 8.727165759143073)\n",
      "(11813.396819863705, 2.7355532898708583)\n",
      "(11824.072989887078, 5.283501240648375)\n",
      "(11835.19201623982, 3.5848166406005797)\n",
      "(11845.280167549408, 9.049484045540925)\n",
      "(11860.312548469763, 8.893515546870724)\n",
      "(11876.793730887739, 5.598449628191859)\n",
      "(11891.808337379494, 9.896935263053326)\n",
      "(11910.448336978441, 8.77294601173893)\n",
      "(11930.069176193598, 4.64835103210966)\n",
      "(11945.581294169018, 6.498011098536558)\n",
      "(11960.921719862257, 4.613605610227787)\n",
      "(11974.506404921336, 5.826819535576082)\n",
      "(11987.722707921916, 3.0579378015740044)\n",
      "(11997.786097009077, 4.870897991133646)\n",
      "(12008.581240701787, 3.144223888271764)\n",
      "(12017.559652192092, 7.286090108567878)\n",
      "(12029.971335266016, 4.962665330393)\n",
      "(12041.454432338216, 5.99749240570106)\n",
      "(12054.122189682264, 6.856332120176939)\n",
      "(12068.081857086887, 6.425439235092297)\n",
      "(12082.632510871612, 8.148610324578875)\n",
      "(12098.7711910213, 2.5962545555165812)\n",
      "(12110.497145328656, 8.874819137433281)\n",
      "(12126.363921418182, 3.0678727511404063)\n",
      "(12138.056862351374, 9.661158941734623)\n",
      "(12154.489016418285, 6.228172434845076)\n",
      "(12169.308348269838, 6.135083546065556)\n",
      "(12184.31983636251, 2.383926293253955)\n",
      "(12194.876226192742, 8.174383168030811)\n",
      "(12209.776875253145, 3.389268362864507)\n",
      "(12220.827382671263, 7.367046815798282)\n",
      "(12234.436856340364, 2.1750597826271605)\n",
      "(12243.945576702501, 7.582422382787884)\n",
      "(12257.55340497286, 6.193349728730586)\n",
      "(12270.782601197048, 3.324829607750763)\n",
      "(12281.748754105576, 3.55050555117373)\n",
      "(12291.356741922424, 7.431273055615404)\n",
      "(12304.736366198284, 7.068104488817203)\n",
      "(12318.773486412983, 5.594044371476156)\n",
      "(12331.93126635675, 6.9369392472123215)\n",
      "(12346.589181993444, 8.088422155723569)\n",
      "(12363.26403596326, 3.1745465420837347)\n",
      "(12375.607238656245, 6.578820950737213)\n",
      "(12389.322517282697, 6.72693685133128)\n",
      "(12403.806540178466, 5.4757851627941445)\n",
      "(12417.250055150504, 7.279210385026823)\n",
      "(12431.789084946806, 2.1132240027126707)\n",
      "(12442.364674265942, 3.3779169618856146)\n",
      "(12451.939940351824, 7.892872583751579)\n",
      "(12465.14113904624, 7.645880698432102)\n",
      "(12479.84357643486, 4.04425787589023)\n",
      "(12491.608856228899, 4.195581442396225)\n",
      "(12503.023995047033, 4.922108197075547)\n",
      "(12514.882024615295, 2.0818533339802876)\n",
      "(12523.363699803936, 6.273092171358766)\n",
      "(12534.176168310421, 4.015196593525022)\n",
      "(12544.091505438702, 3.6739485106618917)\n",
      "(12553.368967942824, 6.687196346113827)\n",
      "(12565.216181118416, 8.412510736477097)\n",
      "(12580.455357114157, 3.1241583021203008)\n",
      "(12591.73636267959, 2.1196864013005063)\n",
      "(12600.628887266104, 6.127927599197518)\n",
      "(12612.29861112, 7.826674665843371)\n",
      "(12626.359353442034, 6.501128011032793)\n",
      "(12639.971214579804, 3.8613919022031675)\n",
      "(12651.647981222864, 5.967232346969408)\n",
      "(12664.89520637758, 6.230519068417969)\n",
      "(12678.587089189476, 9.649082498356895)\n",
      "(12695.606082248789, 5.014127657940867)\n",
      "(12709.785677312564, 9.794654534437674)\n",
      "(12728.054832745258, 4.836256520096219)\n",
      "(12743.118166856828, 9.31358344494273)\n",
      "(12761.298111820786, 4.389435616289681)\n",
      "(12775.407913831443, 9.14269149735522)\n",
      "(12793.017845988834, 9.485395004483362)\n",
      "(12811.833379112679, 3.1203775375082694)\n",
      "(12825.704093577942, 5.794165349345625)\n",
      "(12839.383806028465, 7.919260694646282)\n",
      "(12855.440162294215, 9.051405679555888)\n",
      "(12873.059760156151, 8.352540467302642)\n",
      "(12890.650373872952, 3.916575808425838)\n",
      "(12904.899003385077, 6.391730076354216)\n",
      "(12919.879905080232, 8.97171278146365)\n",
      "(12937.251424422086, 8.60011724690115)\n",
      "(12955.117626797402, 3.4169696197281283)\n",
      "(12968.20647364851, 5.226381349829702)\n",
      "(12981.52931976781, 7.580381482641872)\n",
      "(12996.806253666628, 5.166149852872304)\n",
      "(13010.078987231742, 7.814795984316034)\n",
      "(13024.993641231444, 5.128529025510754)\n",
      "(13038.691989840696, 7.566334264216946)\n",
      "(13054.235134372186, 2.450703150643683)\n",
      "(13065.165443296764, 7.997374689944319)\n",
      "(13079.755372436677, 2.3314743978146444)\n",
      "(13089.819724600837, 3.322140075758445)\n",
      "(13099.099336079324, 9.730746207356994)\n",
      "(13113.757794759778, 5.947236966154434)\n",
      "(13127.860128392307, 9.228548285493765)\n",
      "(13144.6027071285, 4.456956114846101)\n",
      "(13158.753464275136, 7.618470830136833)\n",
      "(13175.109554407538, 6.824103138776504)\n",
      "(13190.72512946427, 3.3368878635239687)\n",
      "(13202.973507859706, 9.258986924490078)\n",
      "(13218.97164869272, 8.900411859319869)\n",
      "(13236.843569919514, 7.290164761823612)\n",
      "(13253.869312179464, 9.21273491363052)\n",
      "(13272.67605773094, 4.684674230920877)\n",
      "(13288.474054689012, 9.61909010743701)\n",
      "(13307.109017112105, 6.156372945033839)\n",
      "(13323.397709868603, 9.664976128412398)\n",
      "(13342.360951379133, 9.61549523835907)\n",
      "(13362.202766369752, 7.478212754383145)\n",
      "(13381.17329671053, 2.4204635221940016)\n",
      "(13394.18555031048, 4.417011663347033)\n",
      "(13406.642400354991, 2.075903790707688)\n",
      "(13415.526283387704, 5.829277245401801)\n",
      "(13425.966608181001, 4.87913449819765)\n",
      "(13436.04069485241, 4.497472010379129)\n",
      "(13446.323204807368, 5.456111208245178)\n",
      "(13457.52693025636, 9.877557949951642)\n",
      "(13474.017340220857, 7.043114956095752)\n",
      "(13489.918132790244, 7.661509679161678)\n",
      "(13506.657241468241, 2.924788810121572)\n",
      "(13519.321101832444, 8.795074840425961)\n",
      "(13535.868697966664, 6.557725479487258)\n",
      "(13551.122890880748, 4.228381953813866)\n",
      "(13563.825326326145, 4.206027818436183)\n",
      "(13575.115180086781, 6.286502044866076)\n",
      "(13588.312603030094, 4.882347416139299)\n",
      "(13600.10885132583, 2.123496083489428)\n",
      "(13608.666205144384, 2.8109677967024664)\n",
      "(13616.579201196448, 5.118528498741594)\n",
      "(13626.288932884381, 6.984683004858376)\n",
      "(13638.277212908279, 2.791090762750054)\n",
      "(13647.394262505579, 3.6968601313612615)\n",
      "(13656.656721370628, 6.219920697931276)\n",
      "(13668.425312172785, 7.6002460432000865)\n",
      "(13682.462514567065, 4.213867562833411)\n",
      "(13694.0322452362, 5.068255009920941)\n",
      "(13706.035201576027, 7.240517632399295)\n",
      "(13720.358514884718, 3.8039843935949653)\n"
     ]
    }
   ],
   "source": [
    "#print(rfid_tags_durations)\n",
    "for i in rfid_tags_durations:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330cc4f-9299-4251-af4f-9686ad069bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
